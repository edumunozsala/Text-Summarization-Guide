{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization Guide \n",
    "# Hyperparameter tunning for training aTransformer model and W&B logging \n",
    "\n",
    "SageMaker Model Tuning is flexible and when used with custom code, allows optimization of arbitrary metrics over arbitrary parameters. Hence be aware that depending on your optimization problem, some or the function below may not apply or would require minor editing to be adapted to your problem\n",
    "\n",
    "This notebook provide code samples demonstrating the flexible analysis capabilities enabled by SageMaker\n",
    "In this notebook we will describe the most relevant steps to start training a custom algorithm in AWS SageMaker, not using a custom container, showing how to deal with experiments and solving some of the problems when facing with custom models when using SageMaker script mode on. Some basics concepts on SageMaker will not be detailed in order to focus on the relevant concepts.\n",
    "\n",
    "Following steps will be explained: \n",
    " \n",
    "1. Create an Experiment and Trial to keep track of our experiments\n",
    "\n",
    "2. Load the training data to our training instance\n",
    "\n",
    "3. Create the scripts to train our custom model, a Transformer.\n",
    "\n",
    "4. Create an Estimator to train our model in a Tensorflow 2.1 container in script mode\n",
    "\n",
    "5. Create metric definitions to keep track of them in SageMaker\n",
    "\n",
    "4. Download the trained model to make predictions\n",
    "\n",
    "5. Resume training using the latest checkpoint from a previous training \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description\n",
    "\n",
    "For this project we will develope notebooks and scripts to train a Transformer Tensorflow 2 model to solve a neural machine translation problem, traslating simple sentences from English to Spanish. This problem and the model is extensively described in my Mdeium post [\"Attention is all you need: Discovering the Transformer paper\"](https://towardsdatascience.com/attention-is-all-you-need-discovering-the-transformer-paper-73e5ff5e0634).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description\n",
    "\n",
    "For this exercise, we’ll use pairs of simple sentences. The source text will be in English, and the target text will be in Spanish, from the Tatoeba project where people contribute, adding translations every day. This is the [link](http://www.manythings.org/anki/) to some translations in different languages. There you can download the Spanish/English `spa_eng.zip` file; it contains 124,457 pairs of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment\n",
    "\n",
    "Let's start by setting up the environment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will import and load the libraries to use in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import boto3\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::223817798831:role/service-role/AmazonSageMaker-ExecutionRole-20200708T194212\n",
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Create a SageMaker session to work with\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# Get the role of our user and the region\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "print(role)\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the variables for data locations\n",
    "data_folder_name='data'\n",
    "train_filename = 'cl_Inshorts.csv'\n",
    "non_breaking_en = 'nonbreaking_prefix.en'\n",
    "\n",
    "# Set the directories for our nodel output\n",
    "trainedmodel_path = 'trained_model'\n",
    "output_data_path = 'output_data'\n",
    "# Set the name of the artifacts that our model generate (model not included) \n",
    "model_info_file = 'model_info.pth'\n",
    "input_vocab_file = 'in_vocab.pkl'\n",
    "output_vocab_file = 'out_vocab.pkl'\n",
    "# Set the absolute path of the train data \n",
    "train_file = os.path.abspath(os.path.join(data_folder_name, train_filename))\n",
    "non_breaking_en_file = os.path.abspath(os.path.join(data_folder_name, non_breaking_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMM_MAX_LENGTH=18\n",
    "TEXT_MAX_LENGTH=70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with Amazon SageMaker training jobs that will run on containers in a new instance or \"vm\", the data has to be share using a S3 Storage folder. For this purpose we define the bucket name and the folder names where our inputs and outputs will be stored. In our case we define:\n",
    "- The **training data** URI: where our input data is located\n",
    "- The **output folder**: where our training saves the outputs fron our model\n",
    "- The **checkpoint folder**: where our model uploads the checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your bucket name\n",
    "bucket_name = 'edumunozsala-ml-sagemaker'\n",
    "project_name = \"ts-transformer\"\n",
    "\n",
    "training_data_folder = r'{}/data'.format(project_name)\n",
    "output_folder = r'{}'.format(project_name)\n",
    "ckpt_folder = r'{}/ckpt'.format(project_name)\n",
    "\n",
    "training_data_uri = r's3://' + bucket_name + r'/' + training_data_folder\n",
    "output_data_uri = r's3://' + bucket_name + r'/' + output_folder\n",
    "ckpt_data_uri = r's3://' + bucket_name + r'/' + ckpt_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://edumunozsala-ml-sagemaker/ts-transformer/data',\n",
       " 's3://edumunozsala-ml-sagemaker/ts-transformer',\n",
       " 's3://edumunozsala-ml-sagemaker/ts-transformer/ckpt')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_uri,output_data_uri,ckpt_data_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can upload to the training data folder in S3 the files necessary for training: training data, non breaking prefixes for the inputs (English) and the non breaking prefixes for the outputs (Spanish). Once uploaded they can be loaded for training in the SageMaker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://edumunozsala-ml-sagemaker/ts-transformer/data/nonbreaking_prefix.en'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(train_file,\n",
    "                              bucket=bucket_name, \n",
    "                              key_prefix=training_data_folder)\n",
    "\n",
    "sagemaker_session.upload_data(non_breaking_en_file,\n",
    "                              bucket=bucket_name, \n",
    "                              key_prefix=training_data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an experiment and trial\n",
    "\n",
    "*Amazon SageMaker Experiments* is a capability of Amazon SageMaker that lets you organize, track, compare, and evaluate your machine learning experiments.\n",
    "\n",
    "Machine learning is an iterative process. You need to experiment with multiple combinations of data, algorithm and parameters, all the while observing the impact of incremental changes on model accuracy. Over time this iterative experimentation can result in thousands of model training runs and model versions. This makes it hard to track the best performing models and their input configurations. It’s also difficult to compare active experiments with past experiments to identify opportunities for further incremental improvements.\n",
    "\n",
    "Experiments will help us to organize and manage all executions, metrics and results of a ML project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker-experiments in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (0.1.25)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from sagemaker-experiments) (1.16.37)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.37 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.19.37)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.37->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.37->boto3>=1.16.27->sagemaker-experiments) (1.25.11)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.37->boto3>=1.16.27->sagemaker-experiments) (1.15.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.37 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.19.37)\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install the library necessary to handle experiments\n",
    "!pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the libraries to handle experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries to work with Experiments in SageMaker\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the experiment and trial name and one tag to help us to identify the reason for this items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the experiment name\n",
    "experiment_name=project_name\n",
    "# Set the trial name \n",
    "trial_name=\"{}-{}\".format(experiment_name,'hp-turner')\n",
    "\n",
    "tags = [{'Key': 'my-experiments', 'Value': 'ts-transformer-hp'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create an experiment to track all the model training iterations. Experiments are a great way to organize your data science work. You can create experiments to organize all your model development work for : a business use case you are addressing (e.g. create experiment named “customer churn prediction”), or a data science team that owns the experiment (e.g. create experiment named “marketing analytics experiment”), or a specific data science and ML project. Think of it as a “folder” for organizing your “files”.\n",
    "\n",
    "We will create a Trial to track each training job run. But this is just a simple example, not intented to explore all the capabilities of the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded experiment  ts-transformer\n",
      "Loaded trial  ts-transformer-hp-turner\n"
     ]
    }
   ],
   "source": [
    "# create the experiment if it doesn't exist\n",
    "try:\n",
    "    training_experiment = Experiment.load(experiment_name=experiment_name)\n",
    "    print('Loaded experiment ',experiment_name)\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        training_experiment = Experiment.create(experiment_name=experiment_name,\n",
    "                                      description = \"Experiment to track Transformer for Text Summarization\", \n",
    "                                      tags = tags)\n",
    "        print('Created experiment ',experiment_name)\n",
    "# create the trial if it doesn't exist\n",
    "try:\n",
    "    single_gpu_trial = Trial.load(trial_name=trial_name)\n",
    "    print('Loaded trial ',trial_name)\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        single_gpu_trial = Trial.create(experiment_name=experiment_name, \n",
    "                             trial_name= trial_name,\n",
    "                             tags = tags)\n",
    "        print('Created trial ',trial_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trackers\n",
    "\n",
    "Another interesting tool to mention, is Tracker objects. They can store information about different types of topics or objects in our model or training process like inputs, parameters, artifacts or metrics. The tracker is attached to a trial, associating the object to the training job. We can record that information and analyze it later on the experiment. **Note** that only parameters, input artifacts, and output artifacts are saved to SageMaker. Metrics are saved to file.\n",
    "\n",
    "As an example, we create a Tracker to register the input data and two parameters about how that data is processed in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Tracker  TextPreprocessing\n"
     ]
    }
   ],
   "source": [
    "from smexperiments.tracker import Tracker\n",
    "# Create the tracker for the inout data\n",
    "tracker_name='TextPreprocessing'\n",
    "trial_comp_name = None # Change to a an exsting TrialComponent to load it\n",
    "\n",
    "try:\n",
    "    tracker = Tracker.load(trial_component_name=trial_comp_name)\n",
    "    print('Loaded Tracker ',tracker_name)\n",
    "except Exception as ex:\n",
    "    tracker = Tracker.create(display_name=tracker_name)\n",
    "    tracker.log_input(name=\"Text Summarization\", media_type=\"s3/uri\", value=inputs)\n",
    "    tracker.log_parameters({\n",
    "        \"Tokenizer\": 'Word',\n",
    "        \"Text Max Length\": 70,\n",
    "        \"Summ Max Length\": 18,\n",
    "        \"Vocab\": 16384\n",
    "    })\n",
    "    print('Created Tracker ',tracker_name)\n",
    "    \n",
    "# Atach the Tracker to the trial\n",
    "single_gpu_trial.add_trial_component(tracker.trial_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last step consist in create the experiment configuration, a dictionary that contains the experiment name, the trial name and the trial component and it will be used to label our training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a configuration definition for our experiment and trial\n",
    "trial_comp_name = 'track-process'\n",
    "# Set the configuration parameters for the experiment\n",
    "experiment_config = {'ExperimentName': training_experiment.experiment_name, \n",
    "                       'TrialName': single_gpu_trial.trial_name,\n",
    "                       'TrialComponentDisplayName': trial_comp_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and show information about the experiment and trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment:  ts-transformer\n"
     ]
    }
   ],
   "source": [
    "print('Experiment: ',training_experiment.experiment_name)\n",
    "# Show the trials in the experiment\n",
    "#for trial in training_experiment.list_trials():\n",
    "    #print('Trial: ',trial.trial_name)\n",
    "\n",
    "#for trial_comp in TrialComponent.list(trial_name=single_gpu_trial.trial_name):\n",
    "#        print('Trial Components: ',trial_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging into W&B\n",
    "\n",
    "Goto your profile page and copy an api key. Add a new cell below and run the following:\n",
    "\n",
    "!wandb login PASTE_API_KEY_HERE\n",
    "\n",
    "You only need to run this once as it writes your credentials in your home directory.\n",
    "\n",
    "W&B looks for a file named secrets.env relative to the training script and loads them into the environment when wandb.init() is called. You can generate a secrets.env file by calling wandb.sagemaker_auth(path=\"source_dir\") in the script you use to launch your experiments. Be sure to add this file to your .gitignore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.10.11-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 15.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.1-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from wandb) (2.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: watchdog>=0.8.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from wandb) (0.10.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from wandb) (5.6.7)\n",
      "Collecting sentry-sdk>=0.4.0\n",
      "  Downloading sentry_sdk-0.19.4-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 60.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from wandb) (5.3.1)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting GitPython>=1.0.0\n",
      "  Using cached GitPython-3.1.11-py3-none-any.whl (159 kB)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: Click>=7.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from wandb) (7.0)\n",
      "Collecting protobuf>=3.12.0\n",
      "  Downloading protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 67.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (1.25.10)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: pathtools>=0.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from watchdog>=0.8.3->wandb) (0.1.2)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.5-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<4,>=3.0.1\n",
      "  Using cached smmap-3.0.4-py2.py3-none-any.whl (25 kB)\n",
      "Building wheels for collected packages: subprocess32, promise\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6489 sha256=66d3a4ddd4bdb61a6680c7f8caa6b9febb26f1be89f1f87231cb47548479e542\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/44/3a/ab/102386d84fe551b6cedb628ed1e74c5f5be76af8b909aeda09\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21495 sha256=b7c13a8febd78681a0cf4f2ab4a58db78d33f0cf6db886f9d8482fa5aa4744a3\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/59/9a/1d/3f1afbbb5122d0410547bf9eb50955f4a7a98e53a6d8b99bd1\n",
      "Successfully built subprocess32 promise\n",
      "Installing collected packages: configparser, sentry-sdk, shortuuid, subprocess32, smmap, gitdb, GitPython, protobuf, docker-pycreds, promise, wandb\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.8.0\n",
      "    Uninstalling protobuf-3.8.0:\n",
      "      Successfully uninstalled protobuf-3.8.0\n",
      "Successfully installed GitPython-3.1.11 configparser-5.0.1 docker-pycreds-0.4.0 gitdb-4.0.5 promise-2.3 protobuf-3.14.0 sentry-sdk-0.19.4 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.10.11\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of google.protobuf.internal.enum_type_wrapper failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __getattr__() requires a code object with 0 free vars, not 1\n",
      "]\n",
      "[autoreload of google.protobuf.descriptor_pool failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: AddDescriptor() requires a code object with 0 free vars, not 1\n",
      "]\n",
      "[autoreload of google.protobuf.descriptor_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/google/protobuf/descriptor_pb2.py\", line 718, in <module>\n",
      "    serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/google/protobuf/descriptor.py\", line 547, in __new__\n",
      "    return _message.default_pool.FindFieldByName(full_name)\n",
      "KeyError: \"Couldn't find field google.protobuf.FieldDescriptorProto.proto3_optional\"\n",
      "]\n",
      "[autoreload of google.protobuf.any_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/google/protobuf/any_pb2.py\", line 71, in <module>\n",
      "    '__module__' : 'google.protobuf.any_pb2'\n",
      "TypeError: A Message class can only inherit from Message\n",
      "]\n",
      "[autoreload of google.protobuf.internal.encoder failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: EncodeVarint() requires a code object with 0 free vars, not 1\n",
      "]\n",
      "[autoreload of google.protobuf.wrappers_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/google/protobuf/wrappers_pb2.py\", line 328, in <module>\n",
      "    '__module__' : 'google.protobuf.wrappers_pb2'\n",
      "TypeError: A Message class can only inherit from Message\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/ec2-user/.netrc\r\n"
     ]
    }
   ],
   "source": [
    "#!wandb login <API_KEY>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W&B looks for a file named `secrets.env` relative to the training script and loads them into the environment when `wandb.init()` is called. You can generate a `secrets.env` file by calling `wandb.sagemaker_auth(path=\"source_dir\")` in the script you use to launch your experiments. Be sure to add this file to your .gitignore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run only once when the secrets.env does not exists\n",
    "#wandb.sagemaker_auth(path=\"Encoder_Decoder_Attention/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for training\n",
    "\n",
    "Script mode is a training script format for TensorFlow that lets you execute any TensorFlow training script in SageMaker with minimal modification. The SageMaker Python SDK handles transferring your script to a SageMaker training instance. On the training instance, SageMaker's native TensorFlow support sets up training-related environment variables and executes your training script. In this tutorial, we use the SageMaker Python SDK to launch a training job.\n",
    "\n",
    "Script mode supports training with a Python script, a Python module, or a shell script.\n",
    "\n",
    "This project's training script was adapted from the Tensorflow model of a Transformer, we develop in a previous post (mentioned previously). We have modified it to handle: \n",
    "- the ``train_file``, ``non_breaking_in``and ``non_breaking_out`` parameters passed in with the values of the training data-set, the non breaking prefixes for the input data and the non breaking prefixes for the output data.\n",
    "\n",
    "- the ``data_dir`` parameter passed in by SageMaker with the value of the enviroment variable `SM_CHANNEL_TRAINING`. This is an S3 path used for input data sharing during training.\n",
    "\n",
    "- the ``model_dir`` parameter passed in by SageMaker. This is an S3 path which can be used for data sharing during distributed training and checkpointing and/or model persistence. We have also added an argument-parsing function to handle processing training-related variables.\n",
    "\n",
    "- the local checkpoint path to store the model checkpoints during training. We use the default value ``/opt/ml/checkpoints`` that will be uploaded to S3. We comment this behavior later when defining our estimator.\n",
    "\n",
    "- At the end of the training job we have added a step to export the trained model, only the weights, to the path stored in the environment variable ``SM_MODEL_DIR``, which always points to ``/opt/ml/model``. This is critical because SageMaker uploads all the model artifacts in this folder to S3 at end of training.\n",
    "\n",
    "- the ``output_data_dir`` parameter passed in by SageMaker with the value of the enviroment variable `SM_OUTPUT_DATA_DIR`. This is a folder path used to save output data from our model. This folder will be uploaded to S3 to store the output.tar.zip. In our case we need to save the tokenizer for the input texts, the tokenizer for the outputs, the input and output vocab size and the tokens for ``eos`` and ``sos``. \n",
    "\n",
    "\n",
    "In addition to the train.py file, our source code folder includes the files:\n",
    "- model.py: Tensorflow model definition\n",
    "- utils.py: utility functions to process the text data \n",
    "- utils_train.py: contains functions to calculate the loss and learning rate scheduler.\n",
    "\n",
    "\n",
    "Here is the entire script for the train.py file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pygmentize 'Transformer/train/train.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our source code needs the tensorflow_dataset library and it is not include in the Tensorflow 2.1. container image provided by SageMaker. To solve this issue we explicitly install it in our train.py file using the command `subprocess.check_call([sys.executable, \"-q\", \"-m\", \"pip\", \"install\", package])`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a training job using the `TensorFlow` estimator\n",
    "\n",
    "The `sagemaker.tensorflow.TensorFlow` estimator handles locating the script mode container where the model will run, uploading your script or source code to a S3 location and creating a SageMaker training job. Let's call out a couple important parameters here:\n",
    "\n",
    "* `source_dir`and `entry_point`, the folder with the source code and the file to run the training.\n",
    "* `framework_version` is the tensorflow version we want to run our code.\n",
    "* `py_version` is set to `'py3'` to indicate that we are using script mode since legacy mode supports only Python 2. Though Python 2 will be deprecated soon, you can use script mode with Python 2 by setting `py_version` to `'py2'` and `script_mode` to `True`.\n",
    "* `code_location` is a S3 folder URI where the `source_dir` will be upload. When the instace starts the content of that folder will be downloaded to a local path, `opt/ml/code`. The `entry_point`, our main code or function, has to be included in that folder.\n",
    "* `output_path` is the S3 path where all the outputs of our training job will be uploaded when the training ends. In our example we will upload to this S3 folder the local content in the folders `SM_MODEL_DIR` and `SM_OUTPUT_DATA_DIR`.\n",
    "* the `checkpoint_local_path`and `checkpoint_s3_uri` parameters will be explained in the next section **\"Resume training from a checkpoint\"**\n",
    "* `script_mode = True` to set script mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.estimator import Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the type of instance to use\n",
    "#instance_type='ml.m4.4xlarge'\n",
    "instance_type='ml.p2.xlarge'\n",
    "#instance_type='local'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for account, region and container image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "container image uri:  223817798831.dkr.ecr.us-east-1.amazonaws.com/ts-transformer\n"
     ]
    }
   ],
   "source": [
    "account = boto3.client('sts').get_caller_identity().get('Account') # aws account \n",
    "#container_image = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account, region, project_name) # algorithm image path in ECR\n",
    "container_image = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account, region, project_name) # algorithm image path in ECR\n",
    "print('container image uri: ',container_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important parameter of our Tensorflow estimator is the `instance_type` that is the type of \"virtual machine\" where the container will run. The values we play around in this project are:\n",
    "- local: The container will run locally on the notebook instance. this is very useful to debug or verify that our estimator definition is correct and the train.py runs successfully. It is much more faster to run the container locally, the start up time for a remote instance is too long when you are coding and debugging.\n",
    "- ml.mX.Yxlarge: It is a CPU instance, when you are running your code for a short train, maybe for validation purposes. Check AWS documentation for a list of alternative instance.\n",
    "- ml.p2.xlarge: This instance use a GPU and it is the preferred one when you want to launch a long running training.\n",
    "\n",
    "When running in local mode, some estimator functionalities are not available like uploading the checkpoints to S3 and its parameters should not be defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we want to mention the definition of metrics. Using a dictionary, we can define a metric name and the regular expression to extract its value from the messages the training script writes on the logs or the stdout during training. Later we can see those metrics in the SageMaker console. We show you how to do it in a following section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics to search for\n",
    "metric_definitions = [{'Name': 'train_loss', 'Regex': 'Train: [0-9a-zA-Z. ]+ Loss ([0-9\\\\.]+)'},\n",
    "                      {'Name': 'val_loss', 'Regex': 'Validation: [0-9a-zA-Z. ]+ Loss ([0-9\\\\.]+)'},\n",
    "                      {'Name': 'val_rouge1', 'Regex': 'Validation: [0-9a-zA-Z. ]+ Rouge1 ([0-9\\\\.]+)'},\n",
    "                      {'Name': 'val_rouge2', 'Regex': 'Validation: [0-9a-zA-Z. ]+ Rouge2 ([0-9\\\\.]+)'},\n",
    "                      {'Name': 'val_rougel', 'Regex': 'Validation: [0-9a-zA-Z. ]+ RougeL ([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define the estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Tensorflow estimator using a Tensorflow 2.1 container\n",
    "estimator = Estimator(#entry_point='train_attention.py',\n",
    "                       #source_dir=\"Encoder_Decoder_Attention/train\",\n",
    "                       role=role,\n",
    "                       instance_count=1,\n",
    "                       instance_type=instance_type,\n",
    "                       image_uri=container_image,\n",
    "                       #framework_version='2.2.0',\n",
    "                       #py_version='py37',\n",
    "                       output_path=output_data_uri,\n",
    "                       code_location=output_data_uri,\n",
    "                       base_job_name='ts-transformer',\n",
    "                       script_mode= True,\n",
    "                       #checkpoint_local_path = 'ckpt', #Use default value /opt/ml/checkpoint\n",
    "                       #checkpoint_s3_uri = ckpt_data_uri,\n",
    "                       metric_definitions = metric_definitions, \n",
    "                       hyperparameters={\n",
    "                        'epochs': 15,\n",
    "                        'nsamples': 54000,\n",
    "                        'n_layers': 6,\n",
    "                        'n_heads':8,\n",
    "                        'text_max-len': 70,\n",
    "                        'summ_max-len': 18,\n",
    "                        'resume': True,\n",
    "                        'train_file': 'cl_Inshorts.csv',\n",
    "                        'non_breaking_in': 'nonbreaking_prefix.en',\n",
    "                        'non_breaking_out': 'nonbreaking_prefix.en'\n",
    "                       })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'223817798831.dkr.ecr.us-east-1.amazonaws.com/ts-transformer'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.training_image_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the hyperparameters tuner object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First round of hyperparamters to tune:\n",
    "hyperparameter_ranges = {\n",
    "    'enc_layers': IntegerParameter(1, 3),\n",
    "    'dec_layers': IntegerParameter(1, 2),\n",
    "    'embedding_dim': CategoricalParameter([128,300]),\n",
    "    'lstm_units': CategoricalParameter([256, 512]),\n",
    "    'learning_rate': ContinuousParameter(0.001, 0.01)\n",
    "}\n",
    "\n",
    "Better results: Enc layers 1, Dec layers 2, embedding dim 300, lstm units 512, learning rate 0.0025\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sweep\n",
    "hyperparameter_ranges = {\n",
    "    'd_model': CategoricalParameter([256, 512]),\n",
    "    'ffn_dim': CategoricalParameter([256, 512, 1024]),\n",
    "    'dropout_rate': ContinuousParameter(0.2, 0.4)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the metric to optimize and how: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'val_rouge2'\n",
    "objective_type = 'Maximize'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the tuner object, setting the hyperparameter ranges, the objetive metric, the count of jobs and the job name prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=5,\n",
    "                            max_parallel_jobs=1,\n",
    "                            objective_type=objective_type,\n",
    "                            early_stopping_type = 'Auto',\n",
    "                            base_tuning_job_name='ts-transformer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the Start a hyperparameter tuning job\n",
    "\n",
    "To start a hyperparameter tuning job, we call `tuner.fit` method with the a few parameter values.\n",
    "\n",
    "- An S3 location is used here as the input. `fit` creates a default channel named `'training'`, which points to this S3 location. In the training script we can access the training data from the local location stored in `SM_CHANNEL_TRAINING`. `fit` accepts a couple other types of input as well. See the API doc [here](https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.EstimatorBase.fit) for details.\n",
    "- `job_name` the name for the training job.\n",
    "- `experiment_config` the dictionary with the name of the experiment and trial to attach this job to.\n",
    "\n",
    "\n",
    "When training starts, the TensorFlow container executes `train.py`, passing `hyperparameters` and `model_dir` from the estimator as script arguments. Because we didn't explicitly define it, `model_dir` defaults to `s3://<DEFAULT_BUCKET>/<TRAINING_JOB_NAME>/model`, so the script execution is as follows:\n",
    "```bash\n",
    "python train.py --model_dir s3://<DEFAULT_BUCKET>/<TRAINING_JOB_NAME>/model --epochs=1 --nsamples=5000 ...\n",
    "```\n",
    "\n",
    "When training is complete, the training job will upload the saved model and other output artifacts to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts-trans-hp-2020-12-31-20-05-12\n"
     ]
    }
   ],
   "source": [
    "# Set the job name and show it\n",
    "job_name = '{}-{}'.format('ts-trans-hp',time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime()))\n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling fit to train a model with TensorFlow 2.1 scroipt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: ts-trans-hp-2020-12-31-20-05-12\n"
     ]
    }
   ],
   "source": [
    "# Call the fit method to launch the training job\n",
    "tuner.fit({'training':training_data_uri}, job_name = job_name, wait=False,\n",
    "              experiment_config = experiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobName': 'ts-att-hp-2020-12-01-20-45-35',\n",
       " 'HyperParameterTuningJobArn': 'arn:aws:sagemaker:us-east-1:223817798831:hyper-parameter-tuning-job/ts-att-hp-2020-12-01-20-45-35',\n",
       " 'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian',\n",
       "  'HyperParameterTuningJobObjective': {'Type': 'Minimize',\n",
       "   'MetricName': 'val_loss'},\n",
       "  'ResourceLimits': {'MaxNumberOfTrainingJobs': 3,\n",
       "   'MaxParallelTrainingJobs': 1},\n",
       "  'ParameterRanges': {'IntegerParameterRanges': [],\n",
       "   'ContinuousParameterRanges': [],\n",
       "   'CategoricalParameterRanges': [{'Name': 'embedding_dim',\n",
       "     'Values': ['\"64\"', '\"128\"']},\n",
       "    {'Name': 'gru_units', 'Values': ['\"256\"', '\"512\"']}]},\n",
       "  'TrainingJobEarlyStoppingType': 'Off'},\n",
       " 'TrainingJobDefinition': {'StaticHyperParameters': {'_tuning_objective_metric': 'val_loss',\n",
       "   'att_units': '128',\n",
       "   'epochs': '3',\n",
       "   'model_dir': '\"s3://edumunozsala-ml-sagemaker/ts-enc-dec-attention/ts-att-hp-2020-12-01-20-45-35/model\"',\n",
       "   'nsamples': '25000',\n",
       "   'resume': 'false',\n",
       "   'sagemaker_container_log_level': '20',\n",
       "   'sagemaker_estimator_class_name': '\"TensorFlow\"',\n",
       "   'sagemaker_estimator_module': '\"sagemaker.tensorflow.estimator\"',\n",
       "   'sagemaker_job_name': '\"ts-att-hp-2020-12-01-20-45-35\"',\n",
       "   'sagemaker_program': '\"train.py\"',\n",
       "   'sagemaker_region': '\"us-east-1\"',\n",
       "   'sagemaker_submit_directory': '\"s3://edumunozsala-ml-sagemaker/ts-enc-dec-attention/ts-att-hp-2020-12-01-20-45-35/source/sourcedir.tar.gz\"',\n",
       "   'train_file': '\"cl_Inshorts.csv\"',\n",
       "   'vocab_size': '16384'},\n",
       "  'AlgorithmSpecification': {'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.2.0-gpu-py37',\n",
       "   'TrainingInputMode': 'File',\n",
       "   'MetricDefinitions': [{'Name': 'train_loss',\n",
       "     'Regex': 'Train: [0-9a-zA-Z. ]+ Loss ([0-9\\\\.]+)'},\n",
       "    {'Name': 'val_loss',\n",
       "     'Regex': 'Validation: [0-9a-zA-Z. ]+ Loss ([0-9\\\\.]+)'},\n",
       "    {'Name': 'val_rouge1',\n",
       "     'Regex': 'Validation: [0-9a-zA-Z. ]+ Rouge1 ([0-9\\\\.]+)'},\n",
       "    {'Name': 'val_rouge2',\n",
       "     'Regex': 'Validation: [0-9a-zA-Z. ]+ Rouge2 ([0-9\\\\.]+)'},\n",
       "    {'Name': 'val_rougel',\n",
       "     'Regex': 'Validation: [0-9a-zA-Z. ]+ RougeL ([0-9\\\\.]+)'},\n",
       "    {'Name': 'ObjectiveMetric',\n",
       "     'Regex': 'Validation: [0-9a-zA-Z. ]+ Loss ([0-9\\\\.]+)'}]},\n",
       "  'RoleArn': 'arn:aws:iam::223817798831:role/service-role/AmazonSageMaker-ExecutionRole-20200708T194212',\n",
       "  'InputDataConfig': [{'ChannelName': 'training',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://edumunozsala-ml-sagemaker/ts-enc-dec-attention/train',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}}}],\n",
       "  'OutputDataConfig': {'S3OutputPath': 's3://edumunozsala-ml-sagemaker/ts-enc-dec-attention'},\n",
       "  'ResourceConfig': {'InstanceType': 'ml.p2.xlarge',\n",
       "   'InstanceCount': 1,\n",
       "   'VolumeSizeInGB': 30},\n",
       "  'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "  'EnableNetworkIsolation': False,\n",
       "  'EnableInterContainerTrafficEncryption': False,\n",
       "  'EnableManagedSpotTraining': False},\n",
       " 'HyperParameterTuningJobStatus': 'InProgress',\n",
       " 'CreationTime': datetime.datetime(2020, 12, 1, 20, 45, 43, 354000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2020, 12, 1, 20, 45, 45, 567000, tzinfo=tzlocal()),\n",
       " 'TrainingJobStatusCounters': {'Completed': 0,\n",
       "  'InProgress': 0,\n",
       "  'RetryableError': 0,\n",
       "  'NonRetryableError': 0,\n",
       "  'Stopped': 0},\n",
       " 'ObjectiveStatusCounters': {'Succeeded': 0, 'Pending': 0, 'Failed': 0},\n",
       " 'ResponseMetadata': {'RequestId': '25a6edae-ff88-439f-8d7c-789ce5a96759',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '25a6edae-ff88-439f-8d7c-789ce5a96759',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '3030',\n",
       "   'date': 'Tue, 01 Dec 2020 20:45:46 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the experiment, then you can view it and its trials from SageMaker Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experiment(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7f7fdaf4d4a8>,experiment_name='ts-enc-dec-attention',experiment_arn='arn:aws:sagemaker:us-east-1:223817798831:experiment/ts-enc-dec-attention',display_name='ts-enc-dec-attention',description='Experiment to track trainings on my tensorflow Transformer Eng-Spa',creation_time=datetime.datetime(2020, 11, 28, 11, 26, 31, 51000, tzinfo=tzlocal()),created_by={},last_modified_time=datetime.datetime(2020, 11, 29, 19, 10, 16, 374000, tzinfo=tzlocal()),last_modified_by={},response_metadata={'RequestId': '9112cee3-4e4d-45c1-bbf5-f6bb4255b97b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '9112cee3-4e4d-45c1-bbf5-f6bb4255b97b', 'content-type': 'application/x-amz-json-1.1', 'content-length': '92', 'date': 'Tue, 01 Dec 2020 10:35:26 GMT'}, 'RetryAttempts': 0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trial\n",
    "single_gpu_trial.save()\n",
    "# Save the experiment\n",
    "training_experiment.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Results of a Hyperparameter Tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You must have already run a hyperparameter tuning job to analyze it here.\n",
    "## The Hyperparameter tuning jobs you have run are listed in the Training section on your SageMaker dashboard.\n",
    "## Copy the name of a completed job you want to analyze from that list.\n",
    "## For example: tuning_job_name = 'mxnet-training-201007-0054'.\n",
    "tuning_job_name = 'ts-att-hp-2020-12-01-20-45-35'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track hyperparameter tuning job progress\n",
    "After you launch a tuning job, you can see its progress by calling describe_tuning_job API. The output from describe-tuning-job is a JSON object that contains information about the current state of the tuning job. You can call list_training_jobs_for_tuning_job to see a detailed list of the training jobs that the tuning job launched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = sagemaker.tuner.HyperparameterTuner.attach(tuning_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_result = tuner.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 training jobs have completed\n"
     ]
    }
   ],
   "source": [
    "#tuning_job_result = sagemaker_session.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuning_job_name)\n",
    "\n",
    "status = tuning_job_result['HyperParameterTuningJobStatus']\n",
    "if status != 'Completed':\n",
    "    print('Reminder: the tuning job has not been completed.')\n",
    "    \n",
    "job_count = tuning_job_result['TrainingJobStatusCounters']['Completed']\n",
    "print(\"%d training jobs have completed\" % job_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show if there are jobs in the tuner already finished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found so far:\n",
      "{'CreationTime': datetime.datetime(2020, 12, 1, 20, 45, 53, tzinfo=tzlocal()),\n",
      " 'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'val_loss',\n",
      "                                                 'Value': 4.423299789428711},\n",
      " 'ObjectiveStatus': 'Succeeded',\n",
      " 'TrainingEndTime': datetime.datetime(2020, 12, 1, 20, 58, 37, tzinfo=tzlocal()),\n",
      " 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:223817798831:training-job/ts-att-hp-2020-12-01-20-45-35-001-4ff9dd24',\n",
      " 'TrainingJobName': 'ts-att-hp-2020-12-01-20-45-35-001-4ff9dd24',\n",
      " 'TrainingJobStatus': 'Completed',\n",
      " 'TrainingStartTime': datetime.datetime(2020, 12, 1, 20, 48, 31, tzinfo=tzlocal()),\n",
      " 'TunedHyperParameters': {'embedding_dim': '\"128\"', 'gru_units': '\"512\"'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "if tuning_job_result.get('BestTrainingJob',None):\n",
    "    print(\"Best model found so far:\")\n",
    "    pprint(tuning_job_result['BestTrainingJob'])\n",
    "else:\n",
    "    print(\"No training jobs have reported results yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show best results of our hyperparameter tunning\n",
    "\n",
    "Fetch all results as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training jobs with valid objective: 3\n",
      "{'lowest': 4.423299789428711, 'highest': 4.478499889373779}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>gru_units</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"128\"</td>\n",
       "      <td>\"512\"</td>\n",
       "      <td>ts-att-hp-2020-12-01-20-45-35-001-4ff9dd24</td>\n",
       "      <td>Completed</td>\n",
       "      <td>4.4233</td>\n",
       "      <td>2020-12-01 20:48:31+00:00</td>\n",
       "      <td>2020-12-01 20:58:37+00:00</td>\n",
       "      <td>606.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"64\"</td>\n",
       "      <td>\"512\"</td>\n",
       "      <td>ts-att-hp-2020-12-01-20-45-35-003-0d5b9ba8</td>\n",
       "      <td>Completed</td>\n",
       "      <td>4.4584</td>\n",
       "      <td>2020-12-01 21:18:06+00:00</td>\n",
       "      <td>2020-12-01 21:28:15+00:00</td>\n",
       "      <td>609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"128\"</td>\n",
       "      <td>\"256\"</td>\n",
       "      <td>ts-att-hp-2020-12-01-20-45-35-002-e7bf3f88</td>\n",
       "      <td>Completed</td>\n",
       "      <td>4.4785</td>\n",
       "      <td>2020-12-01 21:03:01+00:00</td>\n",
       "      <td>2020-12-01 21:12:18+00:00</td>\n",
       "      <td>557.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embedding_dim gru_units                             TrainingJobName  \\\n",
       "2  \"128\"         \"512\"     ts-att-hp-2020-12-01-20-45-35-001-4ff9dd24   \n",
       "0  \"64\"          \"512\"     ts-att-hp-2020-12-01-20-45-35-003-0d5b9ba8   \n",
       "1  \"128\"         \"256\"     ts-att-hp-2020-12-01-20-45-35-002-e7bf3f88   \n",
       "\n",
       "  TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "2  Completed         4.4233              2020-12-01 20:48:31+00:00   \n",
       "0  Completed         4.4584              2020-12-01 21:18:06+00:00   \n",
       "1  Completed         4.4785              2020-12-01 21:03:01+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "2 2020-12-01 20:58:37+00:00  606.0                       \n",
       "0 2020-12-01 21:28:15+00:00  609.0                       \n",
       "1 2020-12-01 21:12:18+00:00  557.0                       "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuner = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "#full_df = tuner.dataframe()\n",
    "# Convert the analytics to a dataframe\n",
    "full_df = tuner.analytics().dataframe()\n",
    "# Set an object to the tuner analytics\n",
    "tuner_analytics = tuner.analytics()\n",
    "\n",
    "is_minimize = (tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['Type'] != 'Maximize')\n",
    "objective_name = tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['MetricName']\n",
    "\n",
    "if len(full_df) > 0:\n",
    "    df = full_df[full_df['FinalObjectiveValue'] > -float('inf')]\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values('FinalObjectiveValue', ascending=is_minimize)\n",
    "        print(\"Number of training jobs with valid objective: %d\" % len(df))\n",
    "        print({\"lowest\":min(df['FinalObjectiveValue']),\"highest\": max(df['FinalObjectiveValue'])})\n",
    "        pd.set_option('display.max_colwidth', -1)  # Don't truncate TrainingJobName        \n",
    "    else:\n",
    "        print(\"No training jobs have reported valid results yet.\")\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will show how the objective metric changes over time, as the tuning job progresses. For Bayesian strategy, you should expect to see a general trend towards better results, but this progress will not be steady as the algorithm needs to balance exploration of new areas of parameter space against exploitation of known good areas. This can give you a sense of whether or not the number of training jobs is sufficient for the complexity of your search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1185\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1185\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1185\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1185' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1185\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1185\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1185\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1185' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1185\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"2246cdba-c61d-47d3-98c1-5510bb63cfbb\" data-root-id=\"1187\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"5be70cd9-cdd2-494a-ab00-f42691c6bbdb\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1196\",\"type\":\"DatetimeAxis\"}],\"center\":[{\"id\":\"1200\",\"type\":\"Grid\"},{\"id\":\"1205\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1201\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"plot_width\":900,\"renderers\":[{\"id\":\"1226\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1249\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1213\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1188\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1192\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1190\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1194\",\"type\":\"LinearScale\"}},\"id\":\"1187\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1209\",\"type\":\"ZoomInTool\"},{\"attributes\":{},\"id\":\"1206\",\"type\":\"PanTool\"},{\"attributes\":{\"days\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]},\"id\":\"1257\",\"type\":\"DaysTicker\"},{\"attributes\":{\"ticker\":{\"id\":\"1197\",\"type\":\"DatetimeTicker\"}},\"id\":\"1200\",\"type\":\"Grid\"},{\"attributes\":{\"days\":[1,4,7,10,13,16,19,22,25,28]},\"id\":\"1258\",\"type\":\"DaysTicker\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"TrainingStartTime\"},\"y\":{\"field\":\"FinalObjectiveValue\"}},\"id\":\"1225\",\"type\":\"Circle\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1186\",\"type\":\"HoverTool\"},{\"id\":\"1206\",\"type\":\"PanTool\"},{\"id\":\"1207\",\"type\":\"CrosshairTool\"},{\"id\":\"1208\",\"type\":\"WheelZoomTool\"},{\"id\":\"1209\",\"type\":\"ZoomInTool\"},{\"id\":\"1210\",\"type\":\"ZoomOutTool\"},{\"id\":\"1211\",\"type\":\"UndoTool\"},{\"id\":\"1212\",\"type\":\"ResetTool\"}]},\"id\":\"1213\",\"type\":\"Toolbar\"},{\"attributes\":{\"days\":[1,8,15,22]},\"id\":\"1259\",\"type\":\"DaysTicker\"},{\"attributes\":{\"formatter\":{\"id\":\"1253\",\"type\":\"DatetimeTickFormatter\"},\"ticker\":{\"id\":\"1197\",\"type\":\"DatetimeTicker\"}},\"id\":\"1196\",\"type\":\"DatetimeAxis\"},{\"attributes\":{},\"id\":\"1211\",\"type\":\"UndoTool\"},{\"attributes\":{\"days\":[1,15]},\"id\":\"1260\",\"type\":\"DaysTicker\"},{\"attributes\":{},\"id\":\"1212\",\"type\":\"ResetTool\"},{\"attributes\":{\"mantissas\":[1,2,5],\"max_interval\":500.0,\"num_minor_ticks\":0},\"id\":\"1254\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"months\":[0,1,2,3,4,5,6,7,8,9,10,11]},\"id\":\"1261\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"formatter\":{\"id\":\"1251\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1202\",\"type\":\"BasicTicker\"}},\"id\":\"1201\",\"type\":\"LinearAxis\"},{\"attributes\":{\"months\":[0,2,4,6,8,10]},\"id\":\"1262\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"1194\",\"type\":\"LinearScale\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1202\",\"type\":\"BasicTicker\"}},\"id\":\"1205\",\"type\":\"Grid\"},{\"attributes\":{\"months\":[0,4,8]},\"id\":\"1263\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"base\":24,\"mantissas\":[1,2,4,6,8,12],\"max_interval\":43200000.0,\"min_interval\":3600000.0,\"num_minor_ticks\":0},\"id\":\"1256\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"months\":[0,6]},\"id\":\"1264\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"TrainingStartTime\"},\"y\":{\"field\":\"FinalObjectiveValue\"}},\"id\":\"1224\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1265\",\"type\":\"YearsTicker\"},{\"attributes\":{},\"id\":\"1266\",\"type\":\"Selection\"},{\"attributes\":{\"callback\":null},\"id\":\"1188\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1267\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"callback\":null},\"id\":\"1190\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data_source\":{\"id\":\"1222\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1224\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1225\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"1227\",\"type\":\"CDSView\"}},\"id\":\"1226\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"data\":{\"FinalObjectiveValue\":{\"__ndarray__\":\"AAAAgHWxEUAAAADAZtURQAAAAOD76RFA\",\"dtype\":\"float64\",\"shape\":[3]},\"TrainingElapsedTimeSeconds\":{\"__ndarray__\":\"AAAAAADwgkAAAAAAAAiDQAAAAAAAaIFA\",\"dtype\":\"float64\",\"shape\":[3]},\"TrainingEndTime\":{\"__ndarray__\":\"AICEmQFid0IAgJlLA2J3QgAA9WECYndC\",\"dtype\":\"float64\",\"shape\":[3]},\"TrainingJobName\":[\"ts-att-hp-2020-12-01-20-45-35-001-4ff9dd24\",\"ts-att-hp-2020-12-01-20-45-35-003-0d5b9ba8\",\"ts-att-hp-2020-12-01-20-45-35-002-e7bf3f88\"],\"TrainingJobStatus\":[\"Completed\",\"Completed\",\"Completed\"],\"TrainingStartTime\":{\"__ndarray__\":\"AICRBQFid0IAAOu2AmJ3QgCA+NkBYndC\",\"dtype\":\"float64\",\"shape\":[3]},\"embedding_dim\":[\"\\\"128\\\"\",\"\\\"64\\\"\",\"\\\"128\\\"\"],\"gru_units\":[\"\\\"512\\\"\",\"\\\"512\\\"\",\"\\\"256\\\"\"],\"index\":[2,0,1]},\"selected\":{\"id\":\"1266\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1267\",\"type\":\"UnionRenderers\"}},\"id\":\"1222\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"text\":\"\"},\"id\":\"1249\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1192\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"1222\",\"type\":\"ColumnDataSource\"}},\"id\":\"1227\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1207\",\"type\":\"CrosshairTool\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"FinalObjectiveValue\",\"@FinalObjectiveValue\"],[\"TrainingJobName\",\"@TrainingJobName\"],[\"embedding_dim\",\"@{embedding_dim}\"],[\"gru_units\",\"@{gru_units}\"]]},\"id\":\"1186\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1202\",\"type\":\"BasicTicker\"},{\"attributes\":{\"num_minor_ticks\":5,\"tickers\":[{\"id\":\"1254\",\"type\":\"AdaptiveTicker\"},{\"id\":\"1255\",\"type\":\"AdaptiveTicker\"},{\"id\":\"1256\",\"type\":\"AdaptiveTicker\"},{\"id\":\"1257\",\"type\":\"DaysTicker\"},{\"id\":\"1258\",\"type\":\"DaysTicker\"},{\"id\":\"1259\",\"type\":\"DaysTicker\"},{\"id\":\"1260\",\"type\":\"DaysTicker\"},{\"id\":\"1261\",\"type\":\"MonthsTicker\"},{\"id\":\"1262\",\"type\":\"MonthsTicker\"},{\"id\":\"1263\",\"type\":\"MonthsTicker\"},{\"id\":\"1264\",\"type\":\"MonthsTicker\"},{\"id\":\"1265\",\"type\":\"YearsTicker\"}]},\"id\":\"1197\",\"type\":\"DatetimeTicker\"},{\"attributes\":{},\"id\":\"1253\",\"type\":\"DatetimeTickFormatter\"},{\"attributes\":{},\"id\":\"1210\",\"type\":\"ZoomOutTool\"},{\"attributes\":{},\"id\":\"1251\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"base\":60,\"mantissas\":[1,2,5,10,15,20,30],\"max_interval\":1800000.0,\"min_interval\":1000.0,\"num_minor_ticks\":0},\"id\":\"1255\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{},\"id\":\"1208\",\"type\":\"WheelZoomTool\"}],\"root_ids\":[\"1187\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
       "  var render_items = [{\"docid\":\"5be70cd9-cdd2-494a-ab00-f42691c6bbdb\",\"roots\":{\"1187\":\"2246cdba-c61d-47d3-98c1-5510bb63cfbb\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1187"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "class HoverHelper():\n",
    "\n",
    "    def __init__(self, tuning_analytics):\n",
    "        self.tuner = tuning_analytics\n",
    "\n",
    "    def hovertool(self):\n",
    "        tooltips = [\n",
    "            (\"FinalObjectiveValue\", \"@FinalObjectiveValue\"),\n",
    "            (\"TrainingJobName\", \"@TrainingJobName\"),\n",
    "        ]\n",
    "        for k in self.tuner.tuning_ranges.keys():\n",
    "            tooltips.append( (k, \"@{%s}\" % k) )\n",
    "\n",
    "        ht = HoverTool(tooltips=tooltips)\n",
    "        return ht\n",
    "\n",
    "    def tools(self, standard_tools='pan,crosshair,wheel_zoom,zoom_in,zoom_out,undo,reset'):\n",
    "        return [self.hovertool(), standard_tools]\n",
    "\n",
    "hover = HoverHelper(tuner_analytics)\n",
    "\n",
    "p = figure(plot_width=900, plot_height=400, tools=hover.tools(), x_axis_type='datetime')\n",
    "p.circle(source=df, x='TrainingStartTime', y='FinalObjectiveValue')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the correlation between objective metric and individual hyperparameters\n",
    "\n",
    "Now you have finished a tuning job, you may want to know the correlation between your objective metric and individual hyperparameters you've selected to tune. Having that insight will help you decide whether it makes sense to adjust search ranges for certain hyperparameters and start another tuning job. For example, if you see a positive trend between objective metric and a numerical hyperparameter, you probably want to set a higher tuning range for that hyperparameter in your next tuning job.\n",
    "\n",
    "The following cell draws a graph for each hyperparameter to show its correlation with your objective metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"4ee81ead-bee2-4254-a5b9-1da61ae86943\" data-root-id=\"1474\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"06828970-53a9-4bbe-b899-9401456344ff\":{\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1389\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"id\":\"1432\",\"subtype\":\"Figure\",\"type\":\"Plot\"}]},\"id\":\"1474\",\"type\":\"Column\"},{\"attributes\":{\"callback\":null,\"factors\":[\"\\\"256\\\"\",\"\\\"512\\\"\"]},\"id\":\"1435\",\"type\":\"FactorRange\"},{\"attributes\":{\"below\":[{\"id\":\"1443\",\"type\":\"CategoricalAxis\"}],\"center\":[{\"id\":\"1446\",\"type\":\"Grid\"},{\"id\":\"1451\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1447\",\"type\":\"LinearAxis\"}],\"plot_height\":500,\"plot_width\":500,\"renderers\":[{\"id\":\"1472\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1433\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1459\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1435\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"1439\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"1437\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1441\",\"type\":\"LinearScale\"}},\"id\":\"1432\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1518\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null},\"id\":\"1437\",\"type\":\"DataRange1d\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1388\",\"type\":\"HoverTool\"},{\"id\":\"1409\",\"type\":\"PanTool\"},{\"id\":\"1410\",\"type\":\"CrosshairTool\"},{\"id\":\"1411\",\"type\":\"WheelZoomTool\"},{\"id\":\"1412\",\"type\":\"ZoomInTool\"},{\"id\":\"1413\",\"type\":\"ZoomOutTool\"},{\"id\":\"1414\",\"type\":\"UndoTool\"},{\"id\":\"1415\",\"type\":\"ResetTool\"}]},\"id\":\"1416\",\"type\":\"Toolbar\"},{\"attributes\":{\"text\":\"Objective vs embedding_dim\"},\"id\":\"1390\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1409\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1439\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"below\":[{\"id\":\"1400\",\"type\":\"CategoricalAxis\"}],\"center\":[{\"id\":\"1403\",\"type\":\"Grid\"},{\"id\":\"1408\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1404\",\"type\":\"LinearAxis\"}],\"plot_height\":500,\"plot_width\":500,\"renderers\":[{\"id\":\"1429\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1390\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1416\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1392\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"1396\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"1394\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1398\",\"type\":\"LinearScale\"}},\"id\":\"1389\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1410\",\"type\":\"CrosshairTool\"},{\"attributes\":{},\"id\":\"1441\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"1468\",\"type\":\"ColumnDataSource\"}},\"id\":\"1473\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1411\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"axis_label\":\"gru_units\",\"formatter\":{\"id\":\"1524\",\"type\":\"CategoricalTickFormatter\"},\"ticker\":{\"id\":\"1444\",\"type\":\"CategoricalTicker\"}},\"id\":\"1443\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"FinalObjectiveValue\",\"@FinalObjectiveValue\"],[\"TrainingJobName\",\"@TrainingJobName\"],[\"embedding_dim\",\"@{embedding_dim}\"],[\"gru_units\",\"@{gru_units}\"]]},\"id\":\"1388\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1520\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{},\"id\":\"1412\",\"type\":\"ZoomInTool\"},{\"attributes\":{},\"id\":\"1444\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"1522\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1413\",\"type\":\"ZoomOutTool\"},{\"attributes\":{\"ticker\":{\"id\":\"1444\",\"type\":\"CategoricalTicker\"}},\"id\":\"1446\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1524\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"callback\":null,\"data\":{\"FinalObjectiveValue\":{\"__ndarray__\":\"AAAAgHWxEUAAAADAZtURQAAAAOD76RFA\",\"dtype\":\"float64\",\"shape\":[3]},\"TrainingElapsedTimeSeconds\":{\"__ndarray__\":\"AAAAAADwgkAAAAAAAAiDQAAAAAAAaIFA\",\"dtype\":\"float64\",\"shape\":[3]},\"TrainingEndTime\":{\"__ndarray__\":\"AICEmQFid0IAgJlLA2J3QgAA9WECYndC\",\"dtype\":\"float64\",\"shape\":[3]},\"TrainingJobName\":[\"ts-att-hp-2020-12-01-20-45-35-001-4ff9dd24\",\"ts-att-hp-2020-12-01-20-45-35-003-0d5b9ba8\",\"ts-att-hp-2020-12-01-20-45-35-002-e7bf3f88\"],\"TrainingJobStatus\":[\"Completed\",\"Completed\",\"Completed\"],\"TrainingStartTime\":{\"__ndarray__\":\"AICRBQFid0IAAOu2AmJ3QgCA+NkBYndC\",\"dtype\":\"float64\",\"shape\":[3]},\"embedding_dim\":[\"\\\"128\\\"\",\"\\\"64\\\"\",\"\\\"128\\\"\"],\"gru_units\":[\"\\\"512\\\"\",\"\\\"512\\\"\",\"\\\"256\\\"\"],\"index\":[2,0,1]},\"selected\":{\"id\":\"1525\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1526\",\"type\":\"UnionRenderers\"}},\"id\":\"1425\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1414\",\"type\":\"UndoTool\"},{\"attributes\":{\"axis_label\":\"val_loss\",\"formatter\":{\"id\":\"1522\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1448\",\"type\":\"BasicTicker\"}},\"id\":\"1447\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1525\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1415\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1448\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1458\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1526\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1448\",\"type\":\"BasicTicker\"}},\"id\":\"1451\",\"type\":\"Grid\"},{\"attributes\":{\"data_source\":{\"id\":\"1425\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1427\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1428\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"1430\",\"type\":\"CDSView\"}},\"id\":\"1429\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1527\",\"type\":\"Selection\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"embedding_dim\"},\"y\":{\"field\":\"FinalObjectiveValue\"}},\"id\":\"1427\",\"type\":\"Circle\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"embedding_dim\"},\"y\":{\"field\":\"FinalObjectiveValue\"}},\"id\":\"1428\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1528\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"gru_units\"},\"y\":{\"field\":\"FinalObjectiveValue\"}},\"id\":\"1471\",\"type\":\"Circle\"},{\"attributes\":{\"data_source\":{\"id\":\"1468\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1470\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1471\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"1473\",\"type\":\"CDSView\"}},\"id\":\"1472\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1457\",\"type\":\"UndoTool\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"FinalObjectiveValue\",\"@FinalObjectiveValue\"],[\"TrainingJobName\",\"@TrainingJobName\"],[\"embedding_dim\",\"@{embedding_dim}\"],[\"gru_units\",\"@{gru_units}\"]]},\"id\":\"1431\",\"type\":\"HoverTool\"},{\"attributes\":{\"callback\":null,\"data\":{\"FinalObjectiveValue\":{\"__ndarray__\":\"AAAAgHWxEUAAAADAZtURQAAAAOD76RFA\",\"dtype\":\"float64\",\"shape\":[3]},\"TrainingElapsedTimeSeconds\":{\"__ndarray__\":\"AAAAAADwgkAAAAAAAAiDQAAAAAAAaIFA\",\"dtype\":\"float64\",\"shape\":[3]},\"TrainingEndTime\":{\"__ndarray__\":\"AICEmQFid0IAgJlLA2J3QgAA9WECYndC\",\"dtype\":\"float64\",\"shape\":[3]},\"TrainingJobName\":[\"ts-att-hp-2020-12-01-20-45-35-001-4ff9dd24\",\"ts-att-hp-2020-12-01-20-45-35-003-0d5b9ba8\",\"ts-att-hp-2020-12-01-20-45-35-002-e7bf3f88\"],\"TrainingJobStatus\":[\"Completed\",\"Completed\",\"Completed\"],\"TrainingStartTime\":{\"__ndarray__\":\"AICRBQFid0IAAOu2AmJ3QgCA+NkBYndC\",\"dtype\":\"float64\",\"shape\":[3]},\"embedding_dim\":[\"\\\"128\\\"\",\"\\\"64\\\"\",\"\\\"128\\\"\"],\"gru_units\":[\"\\\"512\\\"\",\"\\\"512\\\"\",\"\\\"256\\\"\"],\"index\":[2,0,1]},\"selected\":{\"id\":\"1527\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1528\",\"type\":\"UnionRenderers\"}},\"id\":\"1468\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1452\",\"type\":\"PanTool\"},{\"attributes\":{\"source\":{\"id\":\"1425\",\"type\":\"ColumnDataSource\"}},\"id\":\"1430\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1396\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"callback\":null},\"id\":\"1394\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1453\",\"type\":\"CrosshairTool\"},{\"attributes\":{},\"id\":\"1398\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1454\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1401\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"1455\",\"type\":\"ZoomInTool\"},{\"attributes\":{\"callback\":null,\"factors\":[\"\\\"64\\\"\",\"\\\"128\\\"\"]},\"id\":\"1392\",\"type\":\"FactorRange\"},{\"attributes\":{\"axis_label\":\"embedding_dim\",\"formatter\":{\"id\":\"1520\",\"type\":\"CategoricalTickFormatter\"},\"ticker\":{\"id\":\"1401\",\"type\":\"CategoricalTicker\"}},\"id\":\"1400\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"axis_label\":\"val_loss\",\"formatter\":{\"id\":\"1518\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1405\",\"type\":\"BasicTicker\"}},\"id\":\"1404\",\"type\":\"LinearAxis\"},{\"attributes\":{\"text\":\"Objective vs gru_units\"},\"id\":\"1433\",\"type\":\"Title\"},{\"attributes\":{\"ticker\":{\"id\":\"1401\",\"type\":\"CategoricalTicker\"}},\"id\":\"1403\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1456\",\"type\":\"ZoomOutTool\"},{\"attributes\":{},\"id\":\"1405\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"gru_units\"},\"y\":{\"field\":\"FinalObjectiveValue\"}},\"id\":\"1470\",\"type\":\"Circle\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1431\",\"type\":\"HoverTool\"},{\"id\":\"1452\",\"type\":\"PanTool\"},{\"id\":\"1453\",\"type\":\"CrosshairTool\"},{\"id\":\"1454\",\"type\":\"WheelZoomTool\"},{\"id\":\"1455\",\"type\":\"ZoomInTool\"},{\"id\":\"1456\",\"type\":\"ZoomOutTool\"},{\"id\":\"1457\",\"type\":\"UndoTool\"},{\"id\":\"1458\",\"type\":\"ResetTool\"}]},\"id\":\"1459\",\"type\":\"Toolbar\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1405\",\"type\":\"BasicTicker\"}},\"id\":\"1408\",\"type\":\"Grid\"}],\"root_ids\":[\"1474\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
       "  var render_items = [{\"docid\":\"06828970-53a9-4bbe-b899-9401456344ff\",\"roots\":{\"1474\":\"4ee81ead-bee2-4254-a5b9-1da61ae86943\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1474"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ranges = tuner.tuning_ranges\n",
    "ranges = tuner_analytics.tuning_ranges\n",
    "figures = []\n",
    "for hp_name, hp_range in ranges.items():\n",
    "    categorical_args = {}\n",
    "    if hp_range.get('Values'):\n",
    "        # This is marked as categorical.  Check if all options are actually numbers.\n",
    "        def is_num(x):\n",
    "            try:\n",
    "                float(x)\n",
    "                return 1\n",
    "            except:\n",
    "                return 0           \n",
    "        vals = hp_range['Values']\n",
    "        if sum([is_num(x) for x in vals]) == len(vals):\n",
    "            # Bokeh has issues plotting a \"categorical\" range that's actually numeric, so plot as numeric\n",
    "            print(\"Hyperparameter %s is tuned as categorical, but all values are numeric\" % hp_name)\n",
    "        else:\n",
    "            # Set up extra options for plotting categoricals.  A bit tricky when they're actually numbers.\n",
    "            categorical_args['x_range'] = vals\n",
    "\n",
    "    # Now plot it\n",
    "    p = figure(plot_width=500, plot_height=500, \n",
    "               title=\"Objective vs %s\" % hp_name,\n",
    "               tools=hover.tools(),\n",
    "               x_axis_label=hp_name, y_axis_label=objective_name,\n",
    "               **categorical_args)\n",
    "    p.circle(source=df, x=hp_name, y='FinalObjectiveValue')\n",
    "    figures.append(p)\n",
    "show(bokeh.layouts.Column(*figures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show metrics from SageMaker Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can monitor the metrics that a training job emits in real time in the **CloudWatch console**:\n",
    "- Open the CloudWatch console at https://console.aws.amazon.com/cloudwatch/.\n",
    "- Choose Metrics, then choose /aws/sagemaker/TrainingJobs.\n",
    "- Choose TrainingJobName.\n",
    "- On the All metrics tab, choose the names of the training metrics that you want to monitor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Another option is to monitor the metrics by using the **SageMaker console**.\n",
    "- Open the SageMaker console at https://console.aws.amazon.com/sagemaker/.\n",
    "- Choose Training jobs, then choose the training job whose metrics you want to see.\n",
    "- Choose TrainingJobName.\n",
    "- In the Monitor section, you can review the graphs of instance utilization and algorithm metrics\n",
    "\n",
    "It is a simple way to check how your model is \"learning\" during the training stage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore the best training job from the hyperparameter tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach the hyperparameter tuning job\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have just trained a model using our estimator variable in this notebook execution, we can skip this step. But probably you trained your model for hours and now you need to restore your estimator variable from a previous training job. Check for the training job you want to restore the model in SageMaker console, copy the name and paste it in the next section of code. And then you call the `attach` method of the estimator object and now you can continue to work with our training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You must have already run a hyperparameter tuning job to analyze it here.\n",
    "## The Hyperparameter tuning jobs you have run are listed in the Training section on your SageMaker dashboard.\n",
    "## Copy the name of a completed job you want to analyze from that list.\n",
    "## For example: tuning_job_name = 'mxnet-training-201007-0054'.\n",
    "tuning_job_name = 'ts-att-hp-2020-12-01-20-45-35'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the tuning job, attaching it to a HyperparameterTuner object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = sagemaker.tuner.HyperparameterTuner.attach(tuning_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can extract the best estimator from the Tuner object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-12-01 20:58:37 Starting - Preparing the instances for training\n",
      "2020-12-01 20:58:37 Downloading - Downloading input data\n",
      "2020-12-01 20:58:37 Training - Training image download completed. Training in progress.\n",
      "2020-12-01 20:58:37 Uploading - Uploading generated training model\n",
      "2020-12-01 20:58:37 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator = tuner.best_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = estimator.latest_training_job.job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can skip the next cell if the previous estimator.fit command was executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job name where the model will be restored:  ts-enc-dec-attention-single-gpu-2020-12-01-10-16-36\n"
     ]
    }
   ],
   "source": [
    "# Set the job_name\n",
    "job_name = estimator.latest_training_job.job_name\n",
    "print('Job name where the model will be restored: ',estimator.latest_training_job.job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.tensorflow.estimator.TensorFlow at 0x7f304a75ef60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir of model data:  s3://edumunozsala-ml-sagemaker/ts-enc-dec-attention/ts-att-hp-2020-12-01-20-45-35-001-4ff9dd24/output/model.tar.gz\n",
      "Dir of output data:  s3://edumunozsala-ml-sagemaker/ts-enc-dec-attention/ts-att-hp-2020-12-01-20-45-35-001-4ff9dd24/output/model.tar.gz\n",
      "Buck name:  edumunozsala-ml-sagemaker\n"
     ]
    }
   ],
   "source": [
    "print('Dir of model data: ',estimator.model_data)\n",
    "print('Dir of output data: ',estimator.model_data)\n",
    "print('Buck name: ',bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the trained model\n",
    "\n",
    "The estimator object variable `model_data` points to the `model.tar.gz` file which contains the saved model. And the other output files from our model that we need to rebuild and tokenize or detokenize the sentences can be found in the S3 folder `output_path/output/output.tar.gz`. We can download both files and unzip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir to download traned model:  ts-enc-dec-attention/ts-att-hp-2020-12-01-20-45-35-001-4ff9dd24/output/model.tar.gz\n",
      "Dir to download model outputs:  ts-enc-dec-attention/ts-att-hp-2020-12-01-20-45-35-001-4ff9dd24/output/output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Set the model and the output path in S3 to download the data \n",
    "init_model_path = len('s3://')+len(bucket_name)+1\n",
    "s3_model_path=estimator.model_data[init_model_path:]\n",
    "s3_output_data=output_data_uri[init_model_path:]+'/{}/output/output.tar.gz'.format(job_name)\n",
    "print('Dir to download traned model: ', s3_model_path)\n",
    "print('Dir to download model outputs: ', s3_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local dir to download the model:  trained_model\n"
     ]
    }
   ],
   "source": [
    "print('Local dir to download the model: ',trainedmodel_path)\n",
    "print('Local dir to download the outputs: ',output_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.download_data(trainedmodel_path,bucket_name,s3_model_path)\n",
    "sagemaker_session.download_data(output_data_path,bucket_name,s3_output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, extract the information out from the model.tar.gz file return by the training job in SageMaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder.index\n",
      "checkpoint\n",
      "encoder.data-00000-of-00001\n",
      "encoder.index\n",
      "decoder.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "!tar -zxvf $trainedmodel_path/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the files from output.tar.gz without recreating the directory structure, all files will be extracted to the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_vocab.pkl\n",
      "in_vocab.pkl\n",
      "model_info.pth\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf $output_data_path/output.tar.gz #--strip-components=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the tensorflow model and load the model\n",
    "\n",
    "We import the `model.py` file with our model definition but we only have the weights of the model, so we need to rebuild it. The model parameters where saved during training in the `model_info.pth`, we just need to read that file and use the parameters to initiate an empty instance of the model. And then we can load the weights, `load_weights()` into that instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters {'vocab_size_enc': 16384, 'vocab_size_dec': 16384, 'embedding_dim': 128, 'gru_units': 512, 'att_units': 128, 'batch_size': 64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3048c6af28>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Encoder_Decoder_Attention.serve.enc_dec_att_model import Encoder, Decoder\n",
    "\n",
    "# Read the parameters from a dictionary\n",
    "with open(model_info_file, 'rb') as f:\n",
    "    model_info = pickle.load(f)\n",
    "print('Model parameters',model_info)\n",
    "\n",
    "# Create the Encoder\n",
    "encoder = Encoder(model_info['vocab_size_enc'], model_info['embedding_dim'], \n",
    "                      model_info['gru_units'], model_info['batch_size'])\n",
    "decoder = Decoder(model_info['vocab_size_dec'], model_info['embedding_dim'], \n",
    "                      model_info['gru_units'], model_info['batch_size'])\n",
    "#Load the saved model\n",
    "# To do: Use variable to store the model name and pass it in as a hyperparameter of the estimator\n",
    "encoder.load_weights('encoder')\n",
    "decoder.load_weights('decoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some predictions\n",
    "\n",
    "And now everything is ready to make prediction with our trained model:\n",
    "- Import the `predict.py` file with the functions to make a prediction and to translate a sentence. The code was described in the original post.\n",
    "- Read the files and load the tokenizer for the input and output sentences\n",
    "- Call to `traslate` function with the model, the tokenizers, the `sos`and `eos` tokens, the sentence to translate and the max length of the output. It returns the predicted sentence detokenize, a plain text, with the translation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Encoder_Decoder_Attention.serve.predict import predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the input and output tokenizer or vocabularis used in the training. We need them to encode and decode the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the parameters from a dictionary\n",
    "#model_info_path = os.path.join(model_dir, 'model_info.pth')\n",
    "with open(input_vocab_file, 'rb') as f:\n",
    "    tokenizer_inputs = pickle.load(f)\n",
    "\n",
    "with open(output_vocab_file, 'rb') as f:\n",
    "    tokenizer_outputs = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: england pacer james anderson clean bowled cheteshwar pujara with an in-swinging delivery in the visakhapatnam test . the ball came back in after pitching and went through the bat and pad of the batsman to knock out the middle stump . the pacer had bowled a short pitch delivery earlier in the over to push the batsman on to the back foot .\n",
      "Output sentence: <unk> <unk> to <unk> in <unk> <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show some translations\n",
    "sentence = \"england pacer james anderson clean bowled cheteshwar pujara with an in-swinging delivery in the visakhapatnam test . the ball came back in after pitching and went through the bat and pad of the batsman to knock out the middle stump . the pacer had bowled a short pitch delivery earlier in the over to push the batsman on to the back foot .\"\n",
    "print(\"Input sentence: {}\".format(sentence))\n",
    "predicted_sentence, sentence, attention_plot = predict(sentence, encoder, decoder, SUMM_MAX_LENGTH, TEXT_MAX_LENGTH,\n",
    "                             tokenizer_inputs, tokenizer_outputs,model_info['vocab_size_enc'],\n",
    "                               model_info['gru_units'])\n",
    "print(\"Output sentence: {}\".format(predicted_sentence))\n",
    "attention_plot = attention_plot[:len(predicted_sentence.split(' ')), :len(sentence.split(' '))]\n",
    "plot_attention(attention_plot, sentence.split(' '), predicted_sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: This is a really powerful method!\n",
      "Output sentence: ¡Esto es un montón de las carreras de las ocho!\n"
     ]
    }
   ],
   "source": [
    "#Show some translations\n",
    "sentence = \"This is a really powerful method!\"\n",
    "print(\"Input sentence: {}\".format(sentence))\n",
    "predicted_sentence = translate(transformer,sentence,tokenizer_inputs, tokenizer_outputs,15,model_info['sos_token_input'],\n",
    "                               model_info['eos_token_input'],model_info['sos_token_output'],\n",
    "                               model_info['eos_token_output'])\n",
    "print(\"Output sentence: {}\".format(predicted_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_experiment.delete_all(action=\"--force\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- Referencias for experiment and trial\n",
    "https://github.com/shashankprasanna/sagemaker-training-tutorial/blob/master/sagemaker-training-tutorial.ipynb\n",
    "\n",
    "- Analyze the result of a hyperparameter tunning job:\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/analyze_results/HPO_Analyze_TuningJob_Results.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
