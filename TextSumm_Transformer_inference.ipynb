{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy a custom inference code for a Transformer model \n",
    "# Deploy a tensorflow 2.1 model using a custom inference container\n",
    "\n",
    "Some sections of this notebook has been inspired by the tutorial and code:\n",
    "\n",
    "**SageMaker Hello World Inference**\n",
    "\n",
    "https://medium.com/@marckarp101/sagemaker-hello-world-inference-695655a62193\n",
    "https://github.com/studiouser/HelloWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import RealTimePredictor, csv_serializer, csv_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a SageMaker Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'edumunozsala-ml-sagemaker'\n",
    "prefix = 'ts-transformer'\n",
    "model_name='transformer'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download our trained model\n",
    "\n",
    "Previously we trained a Transformer model in Tensorflow 2 and the saved model was saved to AWS S3 folder. Now we want to deploy this trained model in a container and define our own inference code.\n",
    "\n",
    "First, we need to check if the trained saved model is in a .tar.zip file as SageMaker expects. If not, we download the files containing the saved model , zip it and upload it to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://edumunozsala-ml-sagemaker/ts-transformer/transformer/variables/variables.index to transformer/variables/variables.index\n",
      "download: s3://edumunozsala-ml-sagemaker/ts-transformer/transformer/saved_model.pb to transformer/saved_model.pb\n",
      "download: s3://edumunozsala-ml-sagemaker/ts-transformer/transformer/variables/variables.data-00000-of-00001 to transformer/variables/variables.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://$bucket/$prefix/$model_name transformer --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package our Model to deploy to a SageMaker endpoint\n",
    "SageMaker requires our Model to be tared and gzipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_model.pb\n",
      "variables/\n",
      "variables/variables.index\n",
      "variables/variables.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "cd transformer\n",
    "tar -czvf model.tar.gz *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload our Model to S3\n",
    "Now we can upload our gzipped Model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./model.tar.gz to s3://edumunozsala-ml-sagemaker/ts-transformer/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp model.tar.gz s3://$bucket/$prefix/model/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Push our container to ECR\n",
    "We have our custom Model that is now in S3. All we need now is a container that implemenets the hosting requirements and inference logic.\n",
    "An important file to look at is the predictor.py here we coded the logic to deserialize the Model and make a inference from it. SageMaker fetched our Model from S3 and placed it in /opt/ml/model/. Take a look at the get_model() method which uses the code above to load the model from the SageMaker model path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END_TOKEN=[8128]\r",
      "\r\n",
      "SUMM_MAX_LENGTH=30\r",
      "\r\n",
      "\r",
      "\r\n",
      "\r",
      "\r\n",
      "\r",
      "\r\n",
      "class ScoringService(object):\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!sed -n '26,31p' Transformer/container/Files/predictor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/MyNotebooks/Text_Summarization_Enc_Dec_Attention\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  129.3MB\r",
      "\r\n",
      "Step 1/8 : FROM python:3.6\n",
      "3.6: Pulling from library/python\n",
      "6c33745f49b4: Pulling fs layer\n",
      "ef072fc32a84: Pulling fs layer\n",
      "c0afb8e68e0b: Pulling fs layer\n",
      "d599c07d28e6: Pulling fs layer\n",
      "f2ecc74db11a: Pulling fs layer\n",
      "0e7ac7e3db3f: Pulling fs layer\n",
      "dfd5461cd34f: Pulling fs layer\n",
      "e6a2d3233da5: Pulling fs layer\n",
      "099a5f6e48a0: Pulling fs layer\n",
      "d599c07d28e6: Waiting\n",
      "f2ecc74db11a: Waiting\n",
      "0e7ac7e3db3f: Waiting\n",
      "dfd5461cd34f: Waiting\n",
      "e6a2d3233da5: Waiting\n",
      "099a5f6e48a0: Waiting\n",
      "ef072fc32a84: Verifying Checksum\n",
      "ef072fc32a84: Download complete\n",
      "c0afb8e68e0b: Verifying Checksum\n",
      "c0afb8e68e0b: Download complete\n",
      "6c33745f49b4: Verifying Checksum\n",
      "6c33745f49b4: Download complete\n",
      "d599c07d28e6: Verifying Checksum\n",
      "d599c07d28e6: Download complete\n",
      "0e7ac7e3db3f: Verifying Checksum\n",
      "0e7ac7e3db3f: Download complete\n",
      "e6a2d3233da5: Verifying Checksum\n",
      "e6a2d3233da5: Download complete\n",
      "099a5f6e48a0: Verifying Checksum\n",
      "099a5f6e48a0: Download complete\n",
      "dfd5461cd34f: Verifying Checksum\n",
      "dfd5461cd34f: Download complete\n",
      "f2ecc74db11a: Verifying Checksum\n",
      "f2ecc74db11a: Download complete\n",
      "6c33745f49b4: Pull complete\n",
      "ef072fc32a84: Pull complete\n",
      "c0afb8e68e0b: Pull complete\n",
      "d599c07d28e6: Pull complete\n",
      "f2ecc74db11a: Pull complete\n",
      "0e7ac7e3db3f: Pull complete\n",
      "dfd5461cd34f: Pull complete\n",
      "e6a2d3233da5: Pull complete\n",
      "099a5f6e48a0: Pull complete\n",
      "Digest: sha256:4c00d277e8c189175dc460419e17049b98d7d93dd3021700ddb8400646bbc50a\n",
      "Status: Downloaded newer image for python:3.6\n",
      " ---> bd4a91d81d7e\n",
      "Step 2/8 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          python          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 3e3a48a4d6ad\n",
      "Get:1 http://security.debian.org/debian-security buster/updates InRelease [65.4 kB]\n",
      "Get:2 http://deb.debian.org/debian buster InRelease [121 kB]\n",
      "Get:3 http://deb.debian.org/debian buster-updates InRelease [51.9 kB]\n",
      "Get:4 http://security.debian.org/debian-security buster/updates/main amd64 Packages [260 kB]\n",
      "Get:5 http://deb.debian.org/debian buster/main amd64 Packages [7907 kB]\n",
      "Get:6 http://deb.debian.org/debian buster-updates/main amd64 Packages [7860 B]\n",
      "Fetched 8414 kB in 2s (5453 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "python is already the newest version (2.7.16-1).\n",
      "python set to manually installed.\n",
      "wget is already the newest version (1.20.1-1.1).\n",
      "ca-certificates is already the newest version (20200601~deb10u1).\n",
      "The following additional packages will be installed:\n",
      "  libgd3 libgeoip1 libnginx-mod-http-auth-pam libnginx-mod-http-dav-ext\n",
      "  libnginx-mod-http-echo libnginx-mod-http-geoip\n",
      "  libnginx-mod-http-image-filter libnginx-mod-http-subs-filter\n",
      "  libnginx-mod-http-upstream-fair libnginx-mod-http-xslt-filter\n",
      "  libnginx-mod-mail libnginx-mod-stream libxpm4 nginx-common nginx-full\n",
      "Suggested packages:\n",
      "  libgd-tools geoip-bin fcgiwrap nginx-doc ssl-cert\n",
      "Recommended packages:\n",
      "  geoip-database\n",
      "The following NEW packages will be installed:\n",
      "  libgd3 libgeoip1 libnginx-mod-http-auth-pam libnginx-mod-http-dav-ext\n",
      "  libnginx-mod-http-echo libnginx-mod-http-geoip\n",
      "  libnginx-mod-http-image-filter libnginx-mod-http-subs-filter\n",
      "  libnginx-mod-http-upstream-fair libnginx-mod-http-xslt-filter\n",
      "  libnginx-mod-mail libnginx-mod-stream libxpm4 nginx nginx-common nginx-full\n",
      "0 upgraded, 16 newly installed, 0 to remove and 3 not upgraded.\n",
      "Need to get 2038 kB of archives.\n",
      "After this operation, 4130 kB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian buster/main amd64 libxpm4 amd64 1:3.5.12-1 [49.1 kB]\n",
      "Get:2 http://deb.debian.org/debian buster/main amd64 libgd3 amd64 2.2.5-5.2 [136 kB]\n",
      "Get:3 http://deb.debian.org/debian buster/main amd64 libgeoip1 amd64 1.6.12-1 [93.1 kB]\n",
      "Get:4 http://deb.debian.org/debian buster/main amd64 nginx-common all 1.14.2-2+deb10u3 [121 kB]\n",
      "Get:5 http://deb.debian.org/debian buster/main amd64 libnginx-mod-http-auth-pam amd64 1.14.2-2+deb10u3 [92.7 kB]\n",
      "Get:6 http://deb.debian.org/debian buster/main amd64 libnginx-mod-http-dav-ext amd64 1.14.2-2+deb10u3 [100 kB]\n",
      "Get:7 http://deb.debian.org/debian buster/main amd64 libnginx-mod-http-echo amd64 1.14.2-2+deb10u3 [104 kB]\n",
      "Get:8 http://deb.debian.org/debian buster/main amd64 libnginx-mod-http-geoip amd64 1.14.2-2+deb10u3 [94.0 kB]\n",
      "Get:9 http://deb.debian.org/debian buster/main amd64 libnginx-mod-http-image-filter amd64 1.14.2-2+deb10u3 [97.5 kB]\n",
      "Get:10 http://deb.debian.org/debian buster/main amd64 libnginx-mod-http-subs-filter amd64 1.14.2-2+deb10u3 [95.8 kB]\n",
      "Get:11 http://deb.debian.org/debian buster/main amd64 libnginx-mod-http-upstream-fair amd64 1.14.2-2+deb10u3 [95.9 kB]\n",
      "Get:12 http://deb.debian.org/debian buster/main amd64 libnginx-mod-http-xslt-filter amd64 1.14.2-2+deb10u3 [95.8 kB]\n",
      "Get:13 http://deb.debian.org/debian buster/main amd64 libnginx-mod-mail amd64 1.14.2-2+deb10u3 [126 kB]\n",
      "Get:14 http://deb.debian.org/debian buster/main amd64 libnginx-mod-stream amd64 1.14.2-2+deb10u3 [147 kB]\n",
      "Get:15 http://deb.debian.org/debian buster/main amd64 nginx-full amd64 1.14.2-2+deb10u3 [501 kB]\n",
      "Get:16 http://deb.debian.org/debian buster/main amd64 nginx all 1.14.2-2+deb10u3 [88.4 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 2038 kB in 0s (39.2 MB/s)\n",
      "Selecting previously unselected package libxpm4:amd64.\r\n",
      "(Reading database ... \r",
      "(Reading database ... 5%\r",
      "(Reading database ... 10%\r",
      "(Reading database ... 15%\r",
      "(Reading database ... 20%\r",
      "(Reading database ... 25%\r",
      "(Reading database ... 30%\r",
      "(Reading database ... 35%\r",
      "(Reading database ... 40%\r",
      "(Reading database ... 45%\r",
      "(Reading database ... 50%\r",
      "(Reading database ... 55%\r",
      "(Reading database ... 60%\r",
      "(Reading database ... 65%\r",
      "(Reading database ... 70%\r",
      "(Reading database ... 75%\r",
      "(Reading database ... 80%\r",
      "(Reading database ... 85%\r",
      "(Reading database ... 90%\r",
      "(Reading database ... 95%\r",
      "(Reading database ... 100%\r",
      "(Reading database ... 24600 files and directories currently installed.)\r\n",
      "Preparing to unpack .../00-libxpm4_1%3a3.5.12-1_amd64.deb ...\r\n",
      "Unpacking libxpm4:amd64 (1:3.5.12-1) ...\r\n",
      "Selecting previously unselected package libgd3:amd64.\r\n",
      "Preparing to unpack .../01-libgd3_2.2.5-5.2_amd64.deb ...\r\n",
      "Unpacking libgd3:amd64 (2.2.5-5.2) ...\r\n",
      "Selecting previously unselected package libgeoip1:amd64.\r\n",
      "Preparing to unpack .../02-libgeoip1_1.6.12-1_amd64.deb ...\r\n",
      "Unpacking libgeoip1:amd64 (1.6.12-1) ...\r\n",
      "Selecting previously unselected package nginx-common.\r\n",
      "Preparing to unpack .../03-nginx-common_1.14.2-2+deb10u3_all.deb ...\r\n",
      "Unpacking nginx-common (1.14.2-2+deb10u3) ...\r\n",
      "Selecting previously unselected package libnginx-mod-http-auth-pam.\r\n",
      "Preparing to unpack .../04-libnginx-mod-http-auth-pam_1.14.2-2+deb10u3_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-http-auth-pam (1.14.2-2+deb10u3) ...\r\n",
      "Selecting previously unselected package libnginx-mod-http-dav-ext.\r\n",
      "Preparing to unpack .../05-libnginx-mod-http-dav-ext_1.14.2-2+deb10u3_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-http-dav-ext (1.14.2-2+deb10u3) ...\r\n",
      "Selecting previously unselected package libnginx-mod-http-echo.\r\n",
      "Preparing to unpack .../06-libnginx-mod-http-echo_1.14.2-2+deb10u3_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-http-echo (1.14.2-2+deb10u3) ...\r\n",
      "Selecting previously unselected package libnginx-mod-http-geoip.\r\n",
      "Preparing to unpack .../07-libnginx-mod-http-geoip_1.14.2-2+deb10u3_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-http-geoip (1.14.2-2+deb10u3) ...\r\n",
      "Selecting previously unselected package libnginx-mod-http-image-filter.\r\n",
      "Preparing to unpack .../08-libnginx-mod-http-image-filter_1.14.2-2+deb10u3_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-http-image-filter (1.14.2-2+deb10u3) ...\r\n",
      "Selecting previously unselected package libnginx-mod-http-subs-filter.\r\n",
      "Preparing to unpack .../09-libnginx-mod-http-subs-filter_1.14.2-2+deb10u3_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-http-subs-filter (1.14.2-2+deb10u3) ...\r\n",
      "Selecting previously unselected package libnginx-mod-http-upstream-fair.\r\n",
      "Preparing to unpack .../10-libnginx-mod-http-upstream-fair_1.14.2-2+deb10u3_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-http-upstream-fair (1.14.2-2+deb10u3) ...\r\n",
      "Selecting previously unselected package libnginx-mod-http-xslt-filter.\r\n",
      "Preparing to unpack .../11-libnginx-mod-http-xslt-filter_1.14.2-2+deb10u3_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-http-xslt-filter (1.14.2-2+deb10u3) ...\r\n",
      "Selecting previously unselected package libnginx-mod-mail.\r\n",
      "Preparing to unpack .../12-libnginx-mod-mail_1.14.2-2+deb10u3_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-mail (1.14.2-2+deb10u3) ...\r\n",
      "Selecting previously unselected package libnginx-mod-stream.\r\n",
      "Preparing to unpack .../13-libnginx-mod-stream_1.14.2-2+deb10u3_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-stream (1.14.2-2+deb10u3) ...\r\n",
      "Selecting previously unselected package nginx-full.\r\n",
      "Preparing to unpack .../14-nginx-full_1.14.2-2+deb10u3_amd64.deb ...\r\n",
      "Unpacking nginx-full (1.14.2-2+deb10u3) ...\r\n",
      "Selecting previously unselected package nginx.\r\n",
      "Preparing to unpack .../15-nginx_1.14.2-2+deb10u3_all.deb ...\r\n",
      "Unpacking nginx (1.14.2-2+deb10u3) ...\r\n",
      "Setting up libxpm4:amd64 (1:3.5.12-1) ...\r\n",
      "Setting up nginx-common (1.14.2-2+deb10u3) ...\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "Setting up libnginx-mod-http-xslt-filter (1.14.2-2+deb10u3) ...\r\n",
      "Setting up libnginx-mod-http-auth-pam (1.14.2-2+deb10u3) ...\r\n",
      "Setting up libgd3:amd64 (2.2.5-5.2) ...\r\n",
      "Setting up libnginx-mod-http-echo (1.14.2-2+deb10u3) ...\r\n",
      "Setting up libnginx-mod-http-subs-filter (1.14.2-2+deb10u3) ...\r\n",
      "Setting up libgeoip1:amd64 (1.6.12-1) ...\r\n",
      "Setting up libnginx-mod-http-dav-ext (1.14.2-2+deb10u3) ...\r\n",
      "Setting up libnginx-mod-mail (1.14.2-2+deb10u3) ...\r\n",
      "Setting up libnginx-mod-http-image-filter (1.14.2-2+deb10u3) ...\r\n",
      "Setting up libnginx-mod-stream (1.14.2-2+deb10u3) ...\r\n",
      "Setting up libnginx-mod-http-upstream-fair (1.14.2-2+deb10u3) ...\r\n",
      "Setting up libnginx-mod-http-geoip (1.14.2-2+deb10u3) ...\r\n",
      "Setting up nginx-full (1.14.2-2+deb10u3) ...\r\n",
      "invoke-rc.d: could not determine current runlevel\r\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\r\n",
      "Setting up nginx (1.14.2-2+deb10u3) ...\r\n",
      "Processing triggers for libc-bin (2.28-10) ...\r\n",
      "Removing intermediate container 3e3a48a4d6ad\n",
      " ---> 8d9c05d4f832\n",
      "Step 3/8 : RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py &&     pip3 install numpy==1.16.2 tensorflow==2.3 flask gevent gunicorn pandas dill\n",
      " ---> Running in bbb5059795f2\n",
      "\u001b[91m--2021-01-10 18:26:31--  https://bootstrap.pypa.io/get-pip.py\n",
      "\u001b[0m\u001b[91mResolving bootstrap.pypa.io (bootstrap.pypa.io)... \u001b[0m\u001b[91m199.232.64.175, 2a04:4e42:3b::175\n",
      "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|199.232.64.175|:443... \u001b[0m\u001b[91mconnected.\n",
      "\u001b[0m\u001b[91mHTTP request sent, awaiting response... \u001b[0m\u001b[91m200 OK\n",
      "Length: 1886796 (1.8M) [text/x-python]\n",
      "\u001b[0m\u001b[91mSaving to: ‘get-pip.py’\n",
      "\n",
      "     0K .\u001b[0m\u001b[91m......... ......\u001b[0m\u001b[91m.... .......... ...\u001b[0m\u001b[91m.......\u001b[0m\u001b[91m ..........  2% 44.3M 0s\n",
      "    50K ..\u001b[0m\u001b[91m......\u001b[0m\u001b[91m.. .....\u001b[0m\u001b[91m..... ....\u001b[0m\u001b[91m......\u001b[0m\u001b[91m .....\u001b[0m\u001b[91m..... .\u001b[0m\u001b[91m.........  5% 59.2M 0s\n",
      "   100K ........\u001b[0m\u001b[91m.. ...\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.... ....\u001b[0m\u001b[91m...\u001b[0m\u001b[91m..\u001b[0m\u001b[91m. .\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m...\u001b[0m\u001b[91m. .\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m......  8% 36.2M 0s\n",
      "   150K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. ...\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.. ..\u001b[0m\u001b[91m......\u001b[0m\u001b[91m.. .\u001b[0m\u001b[91m....\u001b[0m\u001b[91m....\u001b[0m\u001b[91m. 10% 33.5M 0s\n",
      "   200K ...\u001b[0m\u001b[91m....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m .\u001b[0m\u001b[91m..\u001b[0m\u001b[91m..\u001b[0m\u001b[91m..... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... 13% 51.5M 0s\n",
      "   250K .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. ..\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... 16% 99.1M 0s\n",
      "   300K .........\u001b[0m\u001b[91m. .......... .......... .......... .......... 18%  137M 0s\n",
      "   350K .......\u001b[0m\u001b[91m... .......... .......... .........\u001b[0m\u001b[91m. .......... 21%  184M 0s\n",
      "   400K .....\u001b[0m\u001b[91m..... .......... .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... .......... 24% 77.2M 0s\n",
      "   450K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.. .....\u001b[0m\u001b[91m...\u001b[0m\u001b[91m..\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m.. \u001b[0m\u001b[91m.\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. 27% 47.2M 0s\n",
      "   500K ...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m... .........\u001b[0m\u001b[91m. \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m .\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. .\u001b[0m\u001b[91m..\u001b[0m\u001b[91m....\u001b[0m\u001b[91m... 29%\u001b[0m\u001b[91m 53.8M 0s\n",
      "   550K ..\u001b[0m\u001b[91m...\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m.......\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. .....\u001b[0m\u001b[91m..\u001b[0m\u001b[91m... .\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.......\u001b[0m\u001b[91m 32% 56.4M 0s\n",
      "   600K ...\u001b[0m\u001b[91m....... ........\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..... .....\u001b[0m\u001b[91m....\u001b[0m\u001b[91m. \u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. 35% 49.3M 0s\n",
      "   650K .......... ..\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..... ....\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. ...\u001b[0m\u001b[91m....... 37% 56.0M 0s\n",
      "   700K ....\u001b[0m\u001b[91m...... ....\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. ....\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.... .....\u001b[0m\u001b[91m..... 40%\u001b[0m\u001b[91m 56.7M 0s\u001b[0m\u001b[91m\n",
      "   750K ....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .\u001b[0m\u001b[91m......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. 43% 56.8M 0s\n",
      "   800K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .........\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m 46% 28.9M 0s\n",
      "   850K .......... ....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... \u001b[0m\u001b[91m...\u001b[0m\u001b[91m..\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m 48% 41.9M 0s\n",
      "   900K\u001b[0m\u001b[91m ...\u001b[0m\u001b[91m..\u001b[0m\u001b[91m..\u001b[0m\u001b[91m... .\u001b[0m\u001b[91m..\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... 51% 53.5M\u001b[0m\u001b[91m 0s\n",
      "   950K\u001b[0m\u001b[91m .\u001b[0m\u001b[91m..\u001b[0m\u001b[91m....\u001b[0m\u001b[91m..\u001b[0m\u001b[91m. ...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..... .......... .....\u001b[0m\u001b[91m..... .......\u001b[0m\u001b[91m..\u001b[0m\u001b[91m. 54% 46.0M 0s\n",
      "  1000K\u001b[0m\u001b[91m .\u001b[0m\u001b[91m.\u001b[0m\u001b[91m....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m... ..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. \u001b[0m\u001b[91m.\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m...\u001b[0m\u001b[91m 56% 54.4M 0s\u001b[0m\u001b[91m\n",
      "  1050K\u001b[0m\u001b[91m ..\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.......\u001b[0m\u001b[91m .......... .......\u001b[0m\u001b[91m... .\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...... 59% 54.5M 0s\n",
      "  1100K .\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m .......\u001b[0m\u001b[91m... .......... ....\u001b[0m\u001b[91m...... .\u001b[0m\u001b[91m..\u001b[0m\u001b[91m..\u001b[0m\u001b[91m..\u001b[0m\u001b[91m... 62% 52.0M 0s\u001b[0m\u001b[91m\n",
      "  1150K ...\u001b[0m\u001b[91m....... .......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. ...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..... .......... \u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m....\u001b[0m\u001b[91m.. 65% 38.9M\u001b[0m\u001b[91m 0s\u001b[0m\u001b[91m\n",
      "  1200K\u001b[0m\u001b[91m \u001b[0m\u001b[91m......\u001b[0m\u001b[91m....\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.......\u001b[0m\u001b[91m..\u001b[0m\u001b[91m \u001b[0m\u001b[91m.......... .....\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.. .........\u001b[0m\u001b[91m. 67%\u001b[0m\u001b[91m 50.0M 0s\n",
      "  1250K ......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.. ....\u001b[0m\u001b[91m...... .\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. \u001b[0m\u001b[91m....\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m 70% 53.7M 0s\n",
      "  1300K ...\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m... ........\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.......... \u001b[0m\u001b[91m..\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m... .......... 73% 45.8M 0s\u001b[0m\u001b[91m\n",
      "  1350K .......... .....\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.. ..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.......\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.. 75%\u001b[0m\u001b[91m 37.6M\u001b[0m\u001b[91m 0s\u001b[0m\u001b[91m\n",
      "  1400K\u001b[0m\u001b[91m \u001b[0m\u001b[91m.....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. ..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m......\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m......... ....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m... 78% 30.7M 0s\n",
      "  1450K \u001b[0m\u001b[91m..\u001b[0m\u001b[91m........\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. .\u001b[0m\u001b[91m.\u001b[0m\u001b[91m....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m... \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. 81% 28.5M 0s\n",
      "  1500K\u001b[0m\u001b[91m ...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. ....\u001b[0m\u001b[91m......\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.......\u001b[0m\u001b[91m \u001b[0m\u001b[91m.......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.. ..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m 84% 35.3M 0s\n",
      "  1550K .\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.... .\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m. \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m 86% 26.5M 0s\n",
      "  1600K ..\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.. 89%\u001b[0m\u001b[91m 30.5M\u001b[0m\u001b[91m 0s\u001b[0m\u001b[91m\n",
      "  1650K \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. ......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..... ..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m .\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m....\u001b[0m\u001b[91m 92% 32.6M 0s\n",
      "  1700K .\u001b[0m\u001b[91m..\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.... .\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.. .\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. \u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m 94% 42.9M 0s\u001b[0m\u001b[91m\n",
      "  1750K \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m ...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m..\u001b[0m\u001b[91m ...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.. \u001b[0m\u001b[91m..\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. .\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. 97% 49.1M\u001b[0m\u001b[91m 0s\u001b[0m\u001b[91m\n",
      "  1800K\u001b[0m\u001b[91m ...\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.. .\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.. .\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m...\u001b[0m\u001b[91m \u001b[0m\u001b[91m.\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m...\u001b[0m\u001b[91m..\u001b[0m\u001b[91m \u001b[0m\u001b[91m..  \u001b[0m\u001b[91m \u001b[0m\u001b[91m \u001b[0m\u001b[91m  \u001b[0m\u001b[91m  \u001b[0m\u001b[91m100%\u001b[0m\u001b[91m 46.7M\u001b[0m\u001b[91m=0.04s\u001b[0m\u001b[91m\n",
      "\n",
      "\u001b[0m\u001b[91m2021-01-10 18:26:31 (45.5 MB/s) - ‘get-pip.py’ saved [1886796/1886796]\n",
      "\n",
      "\u001b[0mCollecting pip\n",
      "  Downloading pip-20.3.3-py2.py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.3.3\n",
      "    Uninstalling pip-20.3.3:\n",
      "      Successfully uninstalled pip-20.3.3\n",
      "Successfully installed pip-20.3.3\n",
      "Collecting numpy==1.16.2\n",
      "  Downloading numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3 MB)\n",
      "Collecting tensorflow==2.3\n",
      "  Downloading tensorflow-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/site-packages (from tensorflow==2.3) (0.36.2)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting scipy==1.4.1\n",
      "  Downloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.34.0-cp36-cp36m-manylinux2014_x86_64.whl (4.0 MB)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting six>=1.12.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (51.0.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7-py3-none-any.whl (34 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Collecting flask\n",
      "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting gevent\n",
      "  Downloading gevent-20.12.1.tar.gz (5.9 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting greenlet<2.0,>=0.4.17\n",
      "  Using cached greenlet-0.4.17-cp36-cp36m-manylinux1_x86_64.whl (44 kB)\n",
      "Collecting gunicorn\n",
      "  Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.5-py2.py3-none-any.whl (510 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-3.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Collecting zope.interface\n",
      "  Downloading zope.interface-5.2.0-cp36-cp36m-manylinux2010_x86_64.whl (236 kB)\n",
      "Building wheels for collected packages: termcolor, wrapt, gevent\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=12b89dfc632751ba339d9b3314c5340f601d84fe76026c02918552f28256c095\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=75240 sha256=6e760f3c0756bb7268d0b77dd0017814d9cc0c95f1f95f7484e10ffb055a7426\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "  Building wheel for gevent (PEP 517): started\n",
      "  Building wheel for gevent (PEP 517): still running...\n",
      "  Building wheel for gevent (PEP 517): finished with status 'done'\n",
      "  Created wheel for gevent: filename=gevent-20.12.1-cp36-cp36m-linux_x86_64.whl size=5362597 sha256=6fc419444fa25b72ea99c3e429669cf03b60fde8ca9712f4a254a37ccd278e6e\n",
      "  Stored in directory: /root/.cache/pip/wheels/f5/81/07/5ea206a002bdecf9616c3619100bdc15648eb6213d63c8c8ad\n",
      "Successfully built termcolor wrapt gevent\n",
      "Installing collected packages: urllib3, pyasn1, idna, chardet, certifi, zipp, typing-extensions, six, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, protobuf, numpy, MarkupSafe, markdown, grpcio, google-auth-oauthlib, absl-py, zope.interface, zope.event, wrapt, termcolor, tensorflow-estimator, tensorboard, scipy, pytz, python-dateutil, opt-einsum, keras-preprocessing, Jinja2, itsdangerous, h5py, greenlet, google-pasta, gast, click, astunparse, tensorflow, pandas, gunicorn, gevent, flask, dill\n",
      "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.0 certifi-2020.12.5 chardet-4.0.0 click-7.1.2 dill-0.3.3 flask-1.1.2 gast-0.3.3 gevent-20.12.1 google-auth-1.24.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 greenlet-0.4.17 grpcio-1.34.0 gunicorn-20.0.4 h5py-2.10.0 idna-2.10 importlib-metadata-3.3.0 itsdangerous-1.1.0 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.16.2 oauthlib-3.1.0 opt-einsum-3.3.0 pandas-1.1.5 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 python-dateutil-2.8.1 pytz-2020.5 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7 scipy-1.4.1 six-1.15.0 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.0 tensorflow-estimator-2.3.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.2 werkzeug-1.0.1 wrapt-1.12.1 zipp-3.4.0 zope.event-4.5.0 zope.interface-5.2.0\n",
      "Removing intermediate container bbb5059795f2\n",
      " ---> e34471f2b941\n",
      "Step 4/8 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in f65f8cd4c555\n",
      "Removing intermediate container f65f8cd4c555\n",
      " ---> 89156a0f19bd\n",
      "Step 5/8 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Running in 5596852bc6b0\n",
      "Removing intermediate container 5596852bc6b0\n",
      " ---> 73fbcfc37dfa\n",
      "Step 6/8 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Running in 2f2ba4acc6ad\n",
      "Removing intermediate container 2f2ba4acc6ad\n",
      " ---> f5dbdfef88cb\n",
      "Step 7/8 : COPY Files /opt/program\n",
      " ---> 0060f77655e3\n",
      "Step 8/8 : WORKDIR /opt/program\n",
      " ---> Running in 387fdff556ed\n",
      "Removing intermediate container 387fdff556ed\n",
      " ---> fffe634fda35\n",
      "Successfully built fffe634fda35\n",
      "Successfully tagged ts-transformer-inference:latest\n",
      "The push refers to repository [223817798831.dkr.ecr.us-east-1.amazonaws.com/ts-transformer-inference]\n",
      "a5e633798455: Preparing\n",
      "1af23bdc8960: Preparing\n",
      "57990a2d4fe9: Preparing\n",
      "68f83665b4cd: Preparing\n",
      "0d59c820d67a: Preparing\n",
      "238ce87f4664: Preparing\n",
      "068ec1375999: Preparing\n",
      "da87e334550a: Preparing\n",
      "c5f4367d4a59: Preparing\n",
      "ceecb62b2fcc: Preparing\n",
      "193bc1d68b80: Preparing\n",
      "f0e10b20de19: Preparing\n",
      "238ce87f4664: Waiting\n",
      "068ec1375999: Waiting\n",
      "da87e334550a: Waiting\n",
      "c5f4367d4a59: Waiting\n",
      "ceecb62b2fcc: Waiting\n",
      "193bc1d68b80: Waiting\n",
      "f0e10b20de19: Waiting\n",
      "68f83665b4cd: Layer already exists\n",
      "0d59c820d67a: Layer already exists\n",
      "068ec1375999: Layer already exists\n",
      "238ce87f4664: Layer already exists\n",
      "da87e334550a: Layer already exists\n",
      "c5f4367d4a59: Layer already exists\n",
      "193bc1d68b80: Layer already exists\n",
      "ceecb62b2fcc: Layer already exists\n",
      "f0e10b20de19: Layer already exists\n",
      "a5e633798455: Pushed\n",
      "57990a2d4fe9: Pushed\n",
      "1af23bdc8960: Pushed\n",
      "latest: digest: sha256:3093c07ff910907aa8709a33f3fbccc3432961a05caff6dccf2ec50c2bb2ef03 size: 2850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=ts-transformer-inference\n",
    "\n",
    "cd Transformer/container\n",
    "\n",
    "\n",
    "chmod +x Files/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy our Model to an Endpoint\n",
    "Our container has been pushed to ECR and our Model is in S3 now we have everything we need to Deploy to a SageMaker Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Predictor so we can use the predict() method to invoke our 'model'.\n",
    "class Predictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session=None):\n",
    "        super(Predictor, self).__init__(\n",
    "            endpoint_name, sagemaker_session, csv_serializer, csv_deserializer\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a SageMaker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}-inference:latest'.format(account, region, prefix)\n",
    "\n",
    "sagemaker_model = Model(\n",
    "                        sagemaker_session= sess,\n",
    "                        model_data = \"s3://\"+bucket+\"/\"+prefix+\"/model/model.tar.gz\" , \n",
    "                        image_uri= image,\n",
    "                        role=role,\n",
    "                        predictor_cls= Predictor,\n",
    "                        name= model_name\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy the Model to an Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: transformer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint transformer-2021-01-10-19-15-06-109: Failed. Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint..",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-877d47094bc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'ml.m4.xlarge'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m         )\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict)\u001b[0m\n\u001b[1;32m   3502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3503\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3504\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3506\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   2996\u001b[0m         )\n\u001b[1;32m   2997\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2998\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2999\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_endpoint\u001b[0;34m(self, endpoint, poll)\u001b[0m\n\u001b[1;32m   3288\u001b[0m                 ),\n\u001b[1;32m   3289\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"InService\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             )\n\u001b[1;32m   3292\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint transformer-2021-01-10-19-15-06-109: Failed. Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.."
     ]
    }
   ],
   "source": [
    "predictor = sagemaker_model.deploy(initial_instance_count= 1,instance_type= 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a prediction from our Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(\"Say Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional cleanup\n",
    "When you're done with the endpoint, you'll want to clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Transform Job\n",
    "Now that we have seen the we can deploy our custom pickle file to a RealTime Endpoint and get a prediction, lets now create a Batch Transform Job that will give us batch inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the input data and upload it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile batchdata.csv\n",
    "Say Hello World!\n",
    "Say Hello World!\n",
    "Say Hello World!\n",
    "Say Hello World!\n",
    "Say Hello World!\n",
    "Say Hello World!\n",
    "Say Hello World!\n",
    "Say Hello World!\n",
    "Say Hello World!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 cp batchdata.csv s3://$bucket/$prefix/batchdata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Transfromer from the SageMaker Model and transform the data we created up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_output_folder = \"batch-transform-output\"\n",
    "output_path=\"s3://{}/{}/{}\".format(sess.default_bucket(),\"DEMO-hello-world\",transform_output_folder)\n",
    "\n",
    "transformer = sagemaker_model.transformer(instance_count=1,\n",
    "                               instance_type='ml.m4.xlarge',\n",
    "                               output_path=output_path,\n",
    "                               assemble_with='Line',\n",
    "                               accept='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path=\"s3://{}/{}/{}\".format(sess.default_bucket(),\"DEMO-hello-world\",\"batchdata.csv\")\n",
    "\n",
    "\n",
    "transformer.transform(input_path, content_type='text/csv', split_type='Line')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Batch Transform results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = sess.boto_session.client('s3')\n",
    "s3_client.download_file(sess.default_bucket(), \"DEMO-hello-world/{}/batchdata.csv.out\".format(transform_output_folder), '/tmp/batchdata.csv.out')\n",
    "\n",
    "\n",
    "with open('/tmp/batchdata.csv.out') as f:\n",
    "    results = f.readlines()   \n",
    "print(\"Transform results: \\n{}\".format(''.join(results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
